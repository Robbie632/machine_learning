{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preproccessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import modules and configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "\n",
    "pd.set_option('max.rows', None)\n",
    "pd.set_option('max.columns', None)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_path = '../data/AllData_2_All_Details_3_OutliersRem_1_SupDep_Regions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(data_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations\n",
    "\n",
    "* group_sites -> input : 'superficial_only'|'bed_and_sup'|'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sites = 'superficial_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FH', 'ER', 'WW', 'TC', 'CS', 'BC', 'KQ', 'AR', 'SL', 'FG', 'WB',\n",
       "       'BX', 'PF', 'BM', 'WH', 'SQ', 'BP', 'WN', 'BH', 'PH', 'LB', 'AB',\n",
       "       'LV', 'BR', 'KY', 'BF', 'ST', 'SH', 'CF', 'BG', 'AC', 'CR', 'GH',\n",
       "       'PX', 'WF', 'DH', 'NMAG_Gold', 'NMW_Gold', 'NMWGwern', 'UBSS',\n",
       "       'Cefn', 'Stockley', 'Pucha', 'Woodbury', 'Pimple', 'Wellington',\n",
       "       'Lyonshall', 'SymondsYatE', 'Madawg'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data['Site'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_both_grouped(row):\n",
    "    if row['Geology'] == 'Bedrock':\n",
    "        if row['Site'] == 'WB' or row['Site'] == 'BX':\n",
    "            return('WB_BX')\n",
    "        elif row['Site'] == 'BC' or row['Site'] == 'CS':\n",
    "            return('BC_CS')\n",
    "        elif row['Site'] == 'SQ' or row['Site'] == 'BP':\n",
    "            return('SQ_BP')\n",
    "        else:\n",
    "            return(row['Site'])\n",
    "    elif row['Geology'] == 'Superficial':\n",
    "        if row['Region'] == 'SV' or row['Region'] == 'SE':\n",
    "            return('SV_SE')\n",
    "        else:\n",
    "            return(row['Region'])\n",
    "        \n",
    "def make_superficial_grouped(row):\n",
    "    if row['Geology'] == 'Bedrock':\n",
    "        return(row['Site'])\n",
    "    elif row['Geology'] == 'Superficial':\n",
    "        if row['Region'] == 'SV' or row['Region'] == 'SE':\n",
    "            return('SV_SE')\n",
    "        else:\n",
    "            return(row['Region'])\n",
    "\n",
    "def make_raw(row):\n",
    "    if row['Geology'] == 'Bedrock':\n",
    "        return(row['Site'])\n",
    "    elif row['Geology'] == 'Superficial':\n",
    "        return(row['Region'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['class'] = 'init'   \n",
    "\n",
    "if group_sites == 'bed_and_sup':\n",
    "    my_data['class'] = my_data.apply(make_both_grouped, axis = 1)\n",
    "elif group_sites == 'superficial_only':\n",
    "    my_data['class'] = my_data.apply(make_superficial_grouped, axis = 1)\n",
    "elif group_sites == 'raw':\n",
    "    my_data['class'] = my_data.apply(make_raw, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove '<' signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21695.47it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 18655.19it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20449.21it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 15319.45it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 18073.90it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20314.77it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 17635.77it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 15299.37it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21385.72it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 18733.32it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19705.05it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 15281.25it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19661.39it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 16486.01it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 22274.94it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19694.27it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20379.98it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21484.97it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20789.19it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21412.57it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19951.99it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21364.08it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19403.08it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21172.70it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21523.62it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19096.58it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19827.31it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 21891.76it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 17768.40it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19615.87it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 18997.11it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 16501.56it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19102.59it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 17715.50it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 15542.85it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 18094.44it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 17619.76it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20878.24it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19148.97it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 14397.58it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 17538.24it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19503.76it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19131.67it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 16845.06it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 18970.63it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 18908.22it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 16108.37it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20815.02it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 17719.92it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 16131.67it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 19498.56it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20289.80it/s]\n",
      "Pandas Apply: 100%|██████████| 1606/1606 [00:00<00:00, 20630.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for column_name in my_data.columns.values[9:-1]:\n",
    "    def fill_less_than(row):\n",
    "        if '<' in str(row[column_name]):\n",
    "            return(float(row[column_name].replace('<', '').replace(',','')))\n",
    "        else:\n",
    "            return(float(row[column_name]))\n",
    "    my_data[column_name] = my_data.swifter.apply(fill_less_than, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute na values with variable median, this is more resistant to the effect of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in my_data.columns.values[9:-1]:\n",
    "    my_data[column_name] = my_data[column_name].fillna(my_data[column_name].median()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Geology</th>\n",
       "      <th>Province</th>\n",
       "      <th>Region</th>\n",
       "      <th>Site</th>\n",
       "      <th>SubSite</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Band</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Li7</th>\n",
       "      <th>Be9</th>\n",
       "      <th>B11</th>\n",
       "      <th>Mg24</th>\n",
       "      <th>Al27</th>\n",
       "      <th>Si28</th>\n",
       "      <th>P31</th>\n",
       "      <th>S33</th>\n",
       "      <th>K39</th>\n",
       "      <th>Ca42</th>\n",
       "      <th>Sc45</th>\n",
       "      <th>Ti47</th>\n",
       "      <th>V51</th>\n",
       "      <th>Cr52</th>\n",
       "      <th>Mn55</th>\n",
       "      <th>Fe56</th>\n",
       "      <th>Co59</th>\n",
       "      <th>Ni60</th>\n",
       "      <th>Cu63</th>\n",
       "      <th>Zn68</th>\n",
       "      <th>Ga69</th>\n",
       "      <th>Ge72</th>\n",
       "      <th>As75</th>\n",
       "      <th>Rb85</th>\n",
       "      <th>Sr88</th>\n",
       "      <th>Y89</th>\n",
       "      <th>Zr90</th>\n",
       "      <th>Nb93</th>\n",
       "      <th>Mo95</th>\n",
       "      <th>Cd111</th>\n",
       "      <th>In115</th>\n",
       "      <th>Sn118</th>\n",
       "      <th>Cs133</th>\n",
       "      <th>Ba137</th>\n",
       "      <th>La139</th>\n",
       "      <th>Ce140</th>\n",
       "      <th>Pr141</th>\n",
       "      <th>Nd146</th>\n",
       "      <th>Sm147</th>\n",
       "      <th>Eu153</th>\n",
       "      <th>Gd157</th>\n",
       "      <th>Tb159</th>\n",
       "      <th>Dy163</th>\n",
       "      <th>Ho165</th>\n",
       "      <th>Er166</th>\n",
       "      <th>Tm169</th>\n",
       "      <th>Yb172</th>\n",
       "      <th>Lu175</th>\n",
       "      <th>Hf178</th>\n",
       "      <th>Ta181</th>\n",
       "      <th>Pb208</th>\n",
       "      <th>Th232</th>\n",
       "      <th>U238</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>15.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>48.36</td>\n",
       "      <td>154.63</td>\n",
       "      <td>943.71</td>\n",
       "      <td>464944.18</td>\n",
       "      <td>50.28</td>\n",
       "      <td>538.57</td>\n",
       "      <td>455.94</td>\n",
       "      <td>712.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>15.58</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.62</td>\n",
       "      <td>10.82</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>12.94</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>FH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>44.77</td>\n",
       "      <td>22.42</td>\n",
       "      <td>1077.11</td>\n",
       "      <td>465010.94</td>\n",
       "      <td>70.91</td>\n",
       "      <td>438.20</td>\n",
       "      <td>387.82</td>\n",
       "      <td>515.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>18.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>11.59</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>13.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>FH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>20.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>44.88</td>\n",
       "      <td>42.70</td>\n",
       "      <td>620.21</td>\n",
       "      <td>465295.41</td>\n",
       "      <td>104.47</td>\n",
       "      <td>372.66</td>\n",
       "      <td>363.71</td>\n",
       "      <td>957.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>19.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.21</td>\n",
       "      <td>87.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.53</td>\n",
       "      <td>11.98</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>FH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_FH1_1_2</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_2</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0.73</td>\n",
       "      <td>47.06</td>\n",
       "      <td>162.42</td>\n",
       "      <td>1143.19</td>\n",
       "      <td>465099.89</td>\n",
       "      <td>56367.93</td>\n",
       "      <td>1075.89</td>\n",
       "      <td>547.55</td>\n",
       "      <td>2174.30</td>\n",
       "      <td>0.43</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>152.42</td>\n",
       "      <td>4.84</td>\n",
       "      <td>145.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.02</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>13.16</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>FH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14_FH1_1_2</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_2</td>\n",
       "      <td>17.71</td>\n",
       "      <td>0.32</td>\n",
       "      <td>48.26</td>\n",
       "      <td>33.52</td>\n",
       "      <td>547.22</td>\n",
       "      <td>465027.11</td>\n",
       "      <td>44.44</td>\n",
       "      <td>464.78</td>\n",
       "      <td>278.25</td>\n",
       "      <td>1551.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>11.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.73</td>\n",
       "      <td>25.38</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>FH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Analysis  Geology  Province Region Site SubSite Formation Band   Nodule  \\\n",
       "0  10_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "1  11_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "2  12_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "3  13_FH1_1_2  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_2   \n",
       "4  14_FH1_1_2  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_2   \n",
       "\n",
       "     Li7   Be9    B11    Mg24     Al27       Si28       P31      S33     K39  \\\n",
       "0  15.63  0.12  48.36  154.63   943.71  464944.18     50.28   538.57  455.94   \n",
       "1  11.50  0.09  44.77   22.42  1077.11  465010.94     70.91   438.20  387.82   \n",
       "2  20.05  0.06  44.88   42.70   620.21  465295.41    104.47   372.66  363.71   \n",
       "3  11.16  0.73  47.06  162.42  1143.19  465099.89  56367.93  1075.89  547.55   \n",
       "4  17.71  0.32  48.26   33.52   547.22  465027.11     44.44   464.78  278.25   \n",
       "\n",
       "      Ca42  Sc45   Ti47   V51    Cr52  Mn55    Fe56  Co59  Ni60  Cu63   Zn68  \\\n",
       "0   712.39  0.42  15.58  0.27    3.30  0.69    8.46  0.05  0.80  1.62  10.82   \n",
       "1   515.24  0.44  18.47  0.29    3.45  1.01   11.59  0.11  0.36  0.53   8.93   \n",
       "2   957.89  0.76  19.89  0.55    3.25  1.21   87.99  0.21  1.68  1.53  11.98   \n",
       "3  2174.30  0.43  42.30  0.67  152.42  4.84  145.34  0.30  2.45  5.02  17.15   \n",
       "4  1551.63  0.71  11.18  0.27    2.56  1.73   25.38  0.05  0.80  0.55   9.80   \n",
       "\n",
       "   Ga69  Ge72  As75  Rb85   Sr88   Y89  Zr90  Nb93  Mo95  Cd111  In115  Sn118  \\\n",
       "0  0.25  1.22  0.16  0.43  12.94  0.88  1.51  0.09  0.05   0.02   0.00   0.05   \n",
       "1  0.34  0.85  0.10  0.45  13.22  0.95  1.74  0.07  0.01   0.02   0.00   0.04   \n",
       "2  0.25  1.71  0.13  0.43   8.52  0.87  0.93  0.10  0.02   0.02   0.00   0.05   \n",
       "3  0.35  2.13  0.84  0.76  13.16  0.97  2.00  0.10  0.29   0.18   0.01   0.78   \n",
       "4  0.41  1.41  0.12  0.28   9.90  0.90  0.90  0.08  0.04   0.10   0.00   0.09   \n",
       "\n",
       "   Cs133  Ba137  La139  Ce140  Pr141  Nd146  Sm147  Eu153  Gd157  Tb159  \\\n",
       "0   0.01   6.54   0.84   0.95   0.23   0.87   0.16   0.04   0.16   0.02   \n",
       "1   0.02   8.04   0.92   1.01   0.23   0.98   0.18   0.04   0.18   0.02   \n",
       "2   0.01   3.13   0.90   1.08   0.26   0.84   0.15   0.04   0.19   0.02   \n",
       "3   0.04   8.74   0.93   0.95   0.21   0.75   0.13   0.04   0.25   0.02   \n",
       "4   0.01   2.74   0.97   1.09   0.27   1.00   0.17   0.04   0.19   0.02   \n",
       "\n",
       "   Dy163  Ho165  Er166  Tm169  Yb172  Lu175  Hf178  Ta181  Pb208  Th232  U238  \\\n",
       "0   0.11   0.03   0.06   0.01   0.02   0.00   0.04   0.01   0.24   0.07  0.05   \n",
       "1   0.13   0.03   0.06   0.01   0.04   0.01   0.05   0.00   0.07   0.08  0.04   \n",
       "2   0.14   0.02   0.07   0.01   0.06   0.00   0.02   0.01   0.46   0.05  0.05   \n",
       "3   0.09   0.03   0.05   0.00   0.03   0.00   0.08   0.00   0.64   0.05  0.03   \n",
       "4   0.15   0.03   0.05   0.01   0.05   0.01   0.02   0.01   0.59   0.06  0.09   \n",
       "\n",
       "  class  \n",
       "0    FH  \n",
       "1    FH  \n",
       "2    FH  \n",
       "3    FH  \n",
       "4    FH  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for known data bedrock data for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = my_data[(my_data['Geology']== 'Bedrock') | (my_data['Geology'] == 'Superficial')]\n",
    "test_data = my_data[my_data['Geology']=='Artefacts']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label encode the class to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_formodel = train_data.copy(deep = True)\n",
    "train_data_formodel['class'], uniques = pd.factorize(train_data_formodel['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### order of class labels as numbers 0 through 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FH', 'ER', 'WW', 'TC', 'BC_CS', 'KQ', 'AR', 'SL', 'FG', 'WB_BX', 'PF',\n",
      "       'BM', 'WH', 'SQ_BP', 'WN', 'BH', 'PH', 'LB', 'AB', 'LV', 'SV_SE', 'BA',\n",
      "       'WA', 'MM'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_formodel' (DataFrame)\n",
      "Stored 'train_data' (DataFrame)\n",
      "Stored 'test_data' (DataFrame)\n",
      "Stored 'my_data' (DataFrame)\n",
      "Stored 'uniques' (Index)\n"
     ]
    }
   ],
   "source": [
    "%store train_data_formodel\n",
    "%store train_data\n",
    "%store test_data\n",
    "%store my_data\n",
    "%store uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bedrock = train_data[train_data['Geology'] == 'Bedrock']\n",
    "train_data_superficial = train_data[train_data['Geology'] == 'Superficial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Li7', 'Be9', 'B11', 'Mg24', 'Al27', 'Si28', 'P31', 'S33', 'K39',\n",
       "       'Ca42', 'Sc45', 'Ti47', 'V51', 'Cr52', 'Mn55', 'Fe56', 'Co59',\n",
       "       'Ni60', 'Cu63', 'Zn68', 'Ga69', 'Ge72', 'As75', 'Rb85', 'Sr88',\n",
       "       'Y89', 'Zr90', 'Nb93', 'Mo95', 'Cd111', 'In115', 'Sn118', 'Cs133',\n",
       "       'Ba137', 'La139', 'Ce140', 'Pr141', 'Nd146', 'Sm147', 'Eu153',\n",
       "       'Gd157', 'Tb159', 'Dy163', 'Ho165', 'Er166', 'Tm169', 'Yb172',\n",
       "       'Lu175', 'Hf178', 'Ta181', 'Pb208', 'Th232', 'U238'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_bedrock.columns.values[9:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_data_train = train_data[train_data.columns.values[9:-1]]\n",
    "element_data_train_bedrock = train_data_bedrock[train_data.columns.values[9:-1]]\n",
    "element_data_train_superficial = train_data_superficial[train_data.columns.values[9:-1]]\n",
    "element_data_test = test_data[test_data.columns.values[9:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scaler_train = StandardScaler()\n",
    "my_scaler_train_bedrock = StandardScaler()\n",
    "my_scaler_train_superficial = StandardScaler()\n",
    "my_scaler_test = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_data_train_scaled = my_scaler_train.fit_transform(element_data_train)\n",
    "element_data_train_bedrock_scaled = my_scaler_train_bedrock.fit_transform(element_data_train_bedrock)\n",
    "element_data_train_superficial_scaled = my_scaler_train_superficial.fit_transform(element_data_train_superficial)\n",
    "element_data_test_scaled = my_scaler_test.fit_transform(element_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pca_train = PCA(n_components=element_data_train_scaled.shape[1])\n",
    "\n",
    "my_pca_train_bedrock = PCA(n_components=element_data_train_bedrock_scaled.shape[1])\n",
    "my_pca_train_superficial = PCA(n_components=element_data_train_superficial_scaled.shape[1])\n",
    "\n",
    "my_pca_test = PCA(n_components=element_data_test_scaled.shape[1])\n",
    "\n",
    "element_data_train_pca = my_pca_train.fit_transform(element_data_train_scaled)\n",
    "\n",
    "element_data_train_bedrock_pca = my_pca_train_bedrock.fit_transform(element_data_train_bedrock_scaled)\n",
    "element_data_train_superficial_pca = my_pca_train_superficial.fit_transform(element_data_train_superficial_scaled)\n",
    "\n",
    "element_data_test_pca = my_pca_test.fit_transform(element_data_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_PCs = element_data_train_scaled.shape[1]\n",
    "PC_names = []\n",
    "for i in range(0, no_PCs):\n",
    "    number = i + 1\n",
    "    column_name = 'PC' + str(number)\n",
    "    PC_names.append(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_df_train = pd.DataFrame(data = element_data_train_pca, columns = PC_names)\n",
    "\n",
    "PC_df_bedrock_train = pd.DataFrame(data = element_data_train_bedrock_pca, columns = PC_names)\n",
    "PC_df_superficial_train = pd.DataFrame(data = element_data_train_superficial_pca, columns = PC_names)\n",
    "\n",
    "PC_df_test = pd.DataFrame(data = element_data_test_pca, columns = PC_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 1243 samples in 0.003s...\n",
      "[t-SNE] Computed neighbors for 1243 samples in 0.334s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1243\n",
      "[t-SNE] Computed conditional probabilities for sample 1243 / 1243\n",
      "[t-SNE] Mean sigma: 1.771276\n",
      "[t-SNE] Computed conditional probabilities in 0.104s\n",
      "[t-SNE] Iteration 50: error = 77.7102814, gradient norm = 0.0877779 (50 iterations in 7.398s)\n",
      "[t-SNE] Iteration 100: error = 79.3362198, gradient norm = 0.0623167 (50 iterations in 5.905s)\n",
      "[t-SNE] Iteration 150: error = 80.3517456, gradient norm = 0.0633083 (50 iterations in 5.792s)\n",
      "[t-SNE] Iteration 200: error = 81.3777618, gradient norm = 0.0475815 (50 iterations in 6.071s)\n",
      "[t-SNE] Iteration 250: error = 81.2973557, gradient norm = 0.0627756 (50 iterations in 5.957s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 81.297356\n",
      "[t-SNE] Iteration 300: error = 1.9438406, gradient norm = 0.0007445 (50 iterations in 7.141s)\n",
      "[t-SNE] Iteration 350: error = 1.7708864, gradient norm = 0.0002481 (50 iterations in 8.531s)\n",
      "[t-SNE] Iteration 400: error = 1.6964248, gradient norm = 0.0001375 (50 iterations in 8.912s)\n",
      "[t-SNE] Iteration 450: error = 1.6426413, gradient norm = 0.0000985 (50 iterations in 9.278s)\n",
      "[t-SNE] Iteration 500: error = 1.5911062, gradient norm = 0.0000823 (50 iterations in 9.536s)\n",
      "[t-SNE] Iteration 550: error = 1.5505223, gradient norm = 0.0000576 (50 iterations in 9.566s)\n",
      "[t-SNE] Iteration 600: error = 1.5124346, gradient norm = 0.0000772 (50 iterations in 9.612s)\n",
      "[t-SNE] Iteration 650: error = 1.4805838, gradient norm = 0.0000472 (50 iterations in 9.559s)\n",
      "[t-SNE] Iteration 700: error = 1.4540044, gradient norm = 0.0000380 (50 iterations in 9.487s)\n",
      "[t-SNE] Iteration 750: error = 1.4281291, gradient norm = 0.0000337 (50 iterations in 9.629s)\n",
      "[t-SNE] Error after 750 iterations: 1.428129\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 808 samples in 0.002s...\n",
      "[t-SNE] Computed neighbors for 808 samples in 0.120s...\n",
      "[t-SNE] Computed conditional probabilities for sample 808 / 808\n",
      "[t-SNE] Mean sigma: 1.875790\n",
      "[t-SNE] Computed conditional probabilities in 0.067s\n",
      "[t-SNE] Iteration 50: error = 78.4674301, gradient norm = 0.2092752 (50 iterations in 4.470s)\n",
      "[t-SNE] Iteration 100: error = 83.8887329, gradient norm = 0.1504249 (50 iterations in 4.125s)\n",
      "[t-SNE] Iteration 150: error = 87.1262970, gradient norm = 0.1638989 (50 iterations in 3.606s)\n",
      "[t-SNE] Iteration 200: error = 89.4897842, gradient norm = 0.1614212 (50 iterations in 4.016s)\n",
      "[t-SNE] Iteration 250: error = 89.1291580, gradient norm = 0.1435882 (50 iterations in 3.679s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 89.129158\n",
      "[t-SNE] Iteration 300: error = 2.3708460, gradient norm = 0.0006711 (50 iterations in 3.484s)\n",
      "[t-SNE] Iteration 350: error = 2.1036379, gradient norm = 0.0004959 (50 iterations in 3.758s)\n",
      "[t-SNE] Iteration 400: error = 1.9188310, gradient norm = 0.0002848 (50 iterations in 3.939s)\n",
      "[t-SNE] Iteration 450: error = 1.7983481, gradient norm = 0.0001227 (50 iterations in 3.825s)\n",
      "[t-SNE] Iteration 500: error = 1.7120742, gradient norm = 0.0000854 (50 iterations in 3.870s)\n",
      "[t-SNE] Iteration 550: error = 1.6502745, gradient norm = 0.0000590 (50 iterations in 3.800s)\n",
      "[t-SNE] Iteration 600: error = 1.5926950, gradient norm = 0.0000841 (50 iterations in 3.978s)\n",
      "[t-SNE] Iteration 650: error = 1.5412652, gradient norm = 0.0000448 (50 iterations in 3.838s)\n",
      "[t-SNE] Iteration 700: error = 1.4906379, gradient norm = 0.0000358 (50 iterations in 3.822s)\n",
      "[t-SNE] Iteration 750: error = 1.4506958, gradient norm = 0.0000353 (50 iterations in 3.758s)\n",
      "[t-SNE] Error after 750 iterations: 1.450696\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 435 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 435 samples in 0.038s...\n",
      "[t-SNE] Computed conditional probabilities for sample 435 / 435\n",
      "[t-SNE] Mean sigma: 2.099944\n",
      "[t-SNE] Computed conditional probabilities in 0.038s\n",
      "[t-SNE] Iteration 50: error = 86.1096725, gradient norm = 0.3034197 (50 iterations in 1.717s)\n",
      "[t-SNE] Iteration 100: error = 101.8855286, gradient norm = 0.2500253 (50 iterations in 1.691s)\n",
      "[t-SNE] Iteration 150: error = 111.5773697, gradient norm = 0.2100717 (50 iterations in 1.751s)\n",
      "[t-SNE] Iteration 200: error = 116.8890152, gradient norm = 0.2086329 (50 iterations in 1.712s)\n",
      "[t-SNE] Iteration 250: error = 121.6068344, gradient norm = 0.2025712 (50 iterations in 1.657s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 121.606834\n",
      "[t-SNE] Iteration 300: error = 3.5930889, gradient norm = 0.0006111 (50 iterations in 1.772s)\n",
      "[t-SNE] Iteration 350: error = 3.0421364, gradient norm = 0.0002332 (50 iterations in 1.730s)\n",
      "[t-SNE] Iteration 400: error = 2.7734635, gradient norm = 0.0001354 (50 iterations in 1.718s)\n",
      "[t-SNE] Iteration 450: error = 2.5996356, gradient norm = 0.0000971 (50 iterations in 1.720s)\n",
      "[t-SNE] Iteration 500: error = 2.4754283, gradient norm = 0.0000688 (50 iterations in 1.698s)\n",
      "[t-SNE] Iteration 550: error = 2.3726749, gradient norm = 0.0000564 (50 iterations in 1.732s)\n",
      "[t-SNE] Iteration 600: error = 2.2888572, gradient norm = 0.0000551 (50 iterations in 1.707s)\n",
      "[t-SNE] Iteration 650: error = 2.2187583, gradient norm = 0.0000427 (50 iterations in 1.716s)\n",
      "[t-SNE] Iteration 700: error = 2.1634052, gradient norm = 0.0000340 (50 iterations in 1.710s)\n",
      "[t-SNE] Iteration 750: error = 2.1194227, gradient norm = 0.0000276 (50 iterations in 1.659s)\n",
      "[t-SNE] Error after 750 iterations: 2.119423\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 363 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 363 samples in 0.034s...\n",
      "[t-SNE] Computed conditional probabilities for sample 363 / 363\n",
      "[t-SNE] Mean sigma: 2.333606\n",
      "[t-SNE] Computed conditional probabilities in 0.032s\n",
      "[t-SNE] Iteration 50: error = 89.9666290, gradient norm = 0.2700466 (50 iterations in 1.359s)\n",
      "[t-SNE] Iteration 100: error = 108.5030670, gradient norm = 0.2213182 (50 iterations in 1.401s)\n",
      "[t-SNE] Iteration 150: error = 120.6259232, gradient norm = 0.1987534 (50 iterations in 1.521s)\n",
      "[t-SNE] Iteration 200: error = 124.3188629, gradient norm = 0.1886692 (50 iterations in 1.393s)\n",
      "[t-SNE] Iteration 250: error = 130.6726990, gradient norm = 0.1669541 (50 iterations in 1.342s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 130.672699\n",
      "[t-SNE] Iteration 300: error = 3.7672579, gradient norm = 0.0005643 (50 iterations in 1.385s)\n",
      "[t-SNE] Iteration 350: error = 3.1813085, gradient norm = 0.0002299 (50 iterations in 1.493s)\n",
      "[t-SNE] Iteration 400: error = 2.9063301, gradient norm = 0.0001242 (50 iterations in 1.417s)\n",
      "[t-SNE] Iteration 450: error = 2.7418084, gradient norm = 0.0000843 (50 iterations in 1.382s)\n",
      "[t-SNE] Iteration 500: error = 2.6294050, gradient norm = 0.0000685 (50 iterations in 1.383s)\n",
      "[t-SNE] Iteration 550: error = 2.5443821, gradient norm = 0.0000508 (50 iterations in 1.369s)\n",
      "[t-SNE] Iteration 600: error = 2.4741409, gradient norm = 0.0000425 (50 iterations in 1.358s)\n",
      "[t-SNE] Iteration 650: error = 2.4152691, gradient norm = 0.0000366 (50 iterations in 1.374s)\n",
      "[t-SNE] Iteration 700: error = 2.3708932, gradient norm = 0.0000294 (50 iterations in 1.369s)\n",
      "[t-SNE] Iteration 750: error = 2.3330255, gradient norm = 0.0000253 (50 iterations in 1.364s)\n",
      "[t-SNE] Error after 750 iterations: 2.333025\n"
     ]
    }
   ],
   "source": [
    "my_tsne_train = TSNE(n_components=3, n_iter=750, verbose=3).fit_transform(element_data_train_scaled)\n",
    "\n",
    "my_tsne_bedrock_train = TSNE(n_components=3, n_iter=750, verbose=3).fit_transform(element_data_train_bedrock_scaled)\n",
    "my_tsne_superficial_train = TSNE(n_components=3, n_iter=750, verbose=3).fit_transform(element_data_train_superficial_scaled)\n",
    "\n",
    "my_tsne_test = TSNE(n_components=3, n_iter=750, verbose=3).fit_transform(element_data_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df_train = pd.DataFrame(data = my_tsne_train, columns = ['tsne1', 'tsne2', 'tsne3'])\n",
    "\n",
    "tsne_df_bedrock_train = pd.DataFrame(data = my_tsne_bedrock_train, columns = ['tsne1', 'tsne2', 'tsne3'])\n",
    "tsne_df_superficial_train = pd.DataFrame(data = my_tsne_superficial_train, columns = ['tsne1', 'tsne2', 'tsne3'])\n",
    "\n",
    "tsne_df_test = pd.DataFrame(data = my_tsne_test, columns = ['tsne1', 'tsne2', 'tsne3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'PC_df_train' (DataFrame)\n",
      "Stored 'my_pca_train' (PCA)\n",
      "Stored 'PC_df_bedrock_train' (DataFrame)\n",
      "Stored 'my_pca_train_bedrock' (PCA)\n",
      "Stored 'PC_df_superficial_train' (DataFrame)\n",
      "Stored 'my_pca_train_superficial' (PCA)\n",
      "Stored 'PC_df_test' (DataFrame)\n",
      "Stored 'my_pca_test' (PCA)\n",
      "Stored 'tsne_df_train' (DataFrame)\n",
      "Stored 'tsne_df_bedrock_train' (DataFrame)\n",
      "Stored 'tsne_df_superficial_train' (DataFrame)\n",
      "Stored 'tsne_df_test' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store PC_df_train\n",
    "%store my_pca_train\n",
    "\n",
    "%store PC_df_bedrock_train\n",
    "%store my_pca_train_bedrock\n",
    "\n",
    "%store PC_df_superficial_train\n",
    "%store my_pca_train_superficial\n",
    "\n",
    "%store PC_df_test\n",
    "%store my_pca_test\n",
    "\n",
    "%store tsne_df_train\n",
    "\n",
    "%store tsne_df_bedrock_train\n",
    "%store tsne_df_superficial_train\n",
    "\n",
    "\n",
    "%store tsne_df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "%store -r tsne_df_train\n",
    "tsne_df_train.to_csv('tsne_df_train.csv', index = False)\n",
    "%store -r tsne_df_test\n",
    "tsne_df_test.to_csv('tsne_df_test.csv', index=False)\n",
    "\n",
    "%store -r PC_df_train\n",
    "PC_df_train.to_csv(' PC_df_train.csv', index=False)\n",
    "%store -r PC_df_test\n",
    "PC_df_test.to_csv('PC_df_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
