{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules and configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import pickle\n",
    "\n",
    "from functions.model_data import bestHyperparamaters \n",
    "from functions.postproccessing import process_results\n",
    "\n",
    "pd.set_option('max.rows', None)\n",
    "pd.set_option('max.columns', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load variables stored by data_preproccessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_data_formodel\n",
    "%store -r test_data\n",
    "%store -r my_data\n",
    "%store -r uniques\n",
    "%store -r best_feats\n",
    "%store -r X_test_labeled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Geology</th>\n",
       "      <th>Province</th>\n",
       "      <th>Region</th>\n",
       "      <th>Site</th>\n",
       "      <th>SubSite</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Band</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Li7</th>\n",
       "      <th>Be9</th>\n",
       "      <th>B11</th>\n",
       "      <th>Mg24</th>\n",
       "      <th>Al27</th>\n",
       "      <th>Si28</th>\n",
       "      <th>P31</th>\n",
       "      <th>S33</th>\n",
       "      <th>K39</th>\n",
       "      <th>Ca42</th>\n",
       "      <th>Sc45</th>\n",
       "      <th>Ti47</th>\n",
       "      <th>V51</th>\n",
       "      <th>Cr52</th>\n",
       "      <th>Mn55</th>\n",
       "      <th>Fe56</th>\n",
       "      <th>Co59</th>\n",
       "      <th>Ni60</th>\n",
       "      <th>Cu63</th>\n",
       "      <th>Zn68</th>\n",
       "      <th>Ga69</th>\n",
       "      <th>Ge72</th>\n",
       "      <th>As75</th>\n",
       "      <th>Rb85</th>\n",
       "      <th>Sr88</th>\n",
       "      <th>Y89</th>\n",
       "      <th>Zr90</th>\n",
       "      <th>Nb93</th>\n",
       "      <th>Mo95</th>\n",
       "      <th>Cd111</th>\n",
       "      <th>In115</th>\n",
       "      <th>Sn118</th>\n",
       "      <th>Cs133</th>\n",
       "      <th>Ba137</th>\n",
       "      <th>La139</th>\n",
       "      <th>Ce140</th>\n",
       "      <th>Pr141</th>\n",
       "      <th>Nd146</th>\n",
       "      <th>Sm147</th>\n",
       "      <th>Eu153</th>\n",
       "      <th>Gd157</th>\n",
       "      <th>Tb159</th>\n",
       "      <th>Dy163</th>\n",
       "      <th>Ho165</th>\n",
       "      <th>Er166</th>\n",
       "      <th>Tm169</th>\n",
       "      <th>Yb172</th>\n",
       "      <th>Lu175</th>\n",
       "      <th>Hf178</th>\n",
       "      <th>Ta181</th>\n",
       "      <th>Pb208</th>\n",
       "      <th>Th232</th>\n",
       "      <th>U238</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>15.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>48.36</td>\n",
       "      <td>154.630000</td>\n",
       "      <td>943.71</td>\n",
       "      <td>464944.18</td>\n",
       "      <td>50.280000</td>\n",
       "      <td>538.57</td>\n",
       "      <td>455.94</td>\n",
       "      <td>712.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>15.58</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.62</td>\n",
       "      <td>10.82</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>12.94</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>44.77</td>\n",
       "      <td>43.735431</td>\n",
       "      <td>1077.11</td>\n",
       "      <td>465010.94</td>\n",
       "      <td>70.910000</td>\n",
       "      <td>438.20</td>\n",
       "      <td>387.82</td>\n",
       "      <td>515.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>18.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>11.59</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>13.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>20.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>44.88</td>\n",
       "      <td>42.700000</td>\n",
       "      <td>620.21</td>\n",
       "      <td>465295.41</td>\n",
       "      <td>104.470000</td>\n",
       "      <td>372.66</td>\n",
       "      <td>363.71</td>\n",
       "      <td>957.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>19.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.21</td>\n",
       "      <td>87.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.53</td>\n",
       "      <td>11.98</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_FH1_1_2</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_2</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0.73</td>\n",
       "      <td>47.06</td>\n",
       "      <td>162.420000</td>\n",
       "      <td>1143.19</td>\n",
       "      <td>402596.61</td>\n",
       "      <td>3735.154885</td>\n",
       "      <td>1075.89</td>\n",
       "      <td>547.55</td>\n",
       "      <td>2174.30</td>\n",
       "      <td>0.43</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>152.42</td>\n",
       "      <td>4.84</td>\n",
       "      <td>145.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.02</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>13.16</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14_FH1_1_2</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_2</td>\n",
       "      <td>17.71</td>\n",
       "      <td>0.32</td>\n",
       "      <td>48.26</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>547.22</td>\n",
       "      <td>465027.11</td>\n",
       "      <td>44.440000</td>\n",
       "      <td>464.78</td>\n",
       "      <td>278.25</td>\n",
       "      <td>1551.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>11.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.73</td>\n",
       "      <td>25.38</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Analysis  Geology  Province Region Site SubSite Formation Band   Nodule  \\\n",
       "0  10_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "1  11_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "2  12_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "3  13_FH1_1_2  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_2   \n",
       "4  14_FH1_1_2  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_2   \n",
       "\n",
       "     Li7   Be9    B11        Mg24     Al27       Si28          P31      S33  \\\n",
       "0  15.63  0.12  48.36  154.630000   943.71  464944.18    50.280000   538.57   \n",
       "1  11.50  0.09  44.77   43.735431  1077.11  465010.94    70.910000   438.20   \n",
       "2  20.05  0.06  44.88   42.700000   620.21  465295.41   104.470000   372.66   \n",
       "3  11.16  0.73  47.06  162.420000  1143.19  402596.61  3735.154885  1075.89   \n",
       "4  17.71  0.32  48.26   33.520000   547.22  465027.11    44.440000   464.78   \n",
       "\n",
       "      K39     Ca42  Sc45   Ti47   V51    Cr52  Mn55    Fe56  Co59  Ni60  Cu63  \\\n",
       "0  455.94   712.39  0.42  15.58  0.27    3.30  0.69    8.46  0.05  0.80  1.62   \n",
       "1  387.82   515.24  0.44  18.47  0.29    3.45  1.01   11.59  0.11  0.36  0.53   \n",
       "2  363.71   957.89  0.76  19.89  0.55    3.25  1.21   87.99  0.21  1.68  1.53   \n",
       "3  547.55  2174.30  0.43  42.30  0.67  152.42  4.84  145.34  0.30  2.45  5.02   \n",
       "4  278.25  1551.63  0.71  11.18  0.27    2.56  1.73   25.38  0.05  0.80  0.55   \n",
       "\n",
       "    Zn68  Ga69  Ge72  As75  Rb85   Sr88   Y89  Zr90  Nb93  Mo95  Cd111  In115  \\\n",
       "0  10.82  0.25  1.22  0.16  0.43  12.94  0.88  1.51  0.09  0.05   0.02   0.00   \n",
       "1   8.93  0.34  0.85  0.10  0.45  13.22  0.95  1.74  0.07  0.01   0.02   0.00   \n",
       "2  11.98  0.25  1.71  0.13  0.43   8.52  0.87  0.93  0.10  0.02   0.02   0.00   \n",
       "3  17.15  0.35  2.13  0.84  0.76  13.16  0.97  2.00  0.10  0.29   0.18   0.01   \n",
       "4   9.80  0.41  1.41  0.12  0.28   9.90  0.90  0.90  0.08  0.04   0.10   0.00   \n",
       "\n",
       "   Sn118  Cs133  Ba137  La139  Ce140  Pr141  Nd146  Sm147  Eu153  Gd157  \\\n",
       "0   0.05   0.01   6.54   0.84   0.95   0.23   0.87   0.16   0.04   0.16   \n",
       "1   0.04   0.02   8.04   0.92   1.01   0.23   0.98   0.18   0.04   0.18   \n",
       "2   0.05   0.01   3.13   0.90   1.08   0.26   0.84   0.15   0.04   0.19   \n",
       "3   0.78   0.04   8.74   0.93   0.95   0.21   0.75   0.13   0.04   0.25   \n",
       "4   0.09   0.01   2.74   0.97   1.09   0.27   1.00   0.17   0.04   0.19   \n",
       "\n",
       "   Tb159  Dy163  Ho165  Er166  Tm169  Yb172  Lu175  Hf178  Ta181  Pb208  \\\n",
       "0   0.02   0.11   0.03   0.06   0.01   0.02   0.00   0.04   0.01   0.24   \n",
       "1   0.02   0.13   0.03   0.06   0.01   0.04   0.01   0.05   0.00   0.07   \n",
       "2   0.02   0.14   0.02   0.07   0.01   0.06   0.00   0.02   0.01   0.46   \n",
       "3   0.02   0.09   0.03   0.05   0.00   0.03   0.00   0.08   0.00   0.64   \n",
       "4   0.02   0.15   0.03   0.05   0.01   0.05   0.01   0.02   0.01   0.59   \n",
       "\n",
       "   Th232  U238  class  \n",
       "0   0.07  0.05      0  \n",
       "1   0.08  0.04      0  \n",
       "2   0.05  0.05      0  \n",
       "3   0.05  0.03      0  \n",
       "4   0.06  0.09      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_formodel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configurations\n",
    "\n",
    "* scale -> True|False if set to True then features scaled to all have mean value 0 and standard deviation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_and_dependencies.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts of instances in all classes before oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     105\n",
       "15    100\n",
       "16     61\n",
       "0      53\n",
       "11     45\n",
       "13     36\n",
       "14     36\n",
       "2      36\n",
       "10     30\n",
       "7      30\n",
       "6      30\n",
       "5      27\n",
       "8      27\n",
       "1      24\n",
       "12     21\n",
       "3      18\n",
       "9      17\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_formodel['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class column is stored as the variable y and the variables identified as best by the 2 feature_selection notebook are used as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train_data_formodel[target])\n",
    "X = np.array(np.array(train_data_formodel[best_feats]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the dimensions of the class and features are checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 15)\n",
      "(696,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search is utilised to identify optimum hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   54.9s\n"
     ]
    }
   ],
   "source": [
    "my_optimiser = bestHyperparamaters(X, y)\n",
    "my_optimiser.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = my_optimiser.best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model is built for predicting source of artefacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=16, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2400, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check to see model correctly predicts geological samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_check = best_model.predict(X)\n",
    "sum(train_check == y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When I check the encodings below with that in notebook 1, it is to be correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=16, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=2400, n_jobs=-1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'output_datasets/models/rfc_model.sav'\n",
    "#pickle.dump(best_model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "numbers = [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]\n",
    "sites = ['FH', 'ER', 'WW', 'TC', 'CS', 'KQ', 'AR', 'SL', 'FG', 'WB', 'PF', 'WH',\n",
    "       'SQ', 'WN', 'BH', 'PH', 'LB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    my_dict[i] = sites[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'FH',\n",
       " 1: 'ER',\n",
       " 2: 'WW',\n",
       " 3: 'TC',\n",
       " 4: 'CS',\n",
       " 5: 'KQ',\n",
       " 6: 'AR',\n",
       " 7: 'SL',\n",
       " 8: 'FG',\n",
       " 9: 'WB',\n",
       " 10: 'PF',\n",
       " 11: 'WH',\n",
       " 12: 'SQ',\n",
       " 13: 'WN',\n",
       " 14: 'BH',\n",
       " 15: 'PH',\n",
       " 16: 'LB'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Index(['FH', 'ER', 'WW', 'TC', 'CS', 'KQ', 'AR', 'SL', 'FG', 'WB', 'PF', 'WH',\n",
      "       'SQ', 'WN', 'BH', 'PH', 'LB'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data_formodel[target].unique())\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers =  X_test_labeled_df['Analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 29764.86it/s]\n"
     ]
    }
   ],
   "source": [
    "results = process_results(best_model, X_test_labeled_df, best_feats, uniques, identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_number</th>\n",
       "      <th>FH</th>\n",
       "      <th>ER</th>\n",
       "      <th>WW</th>\n",
       "      <th>TC</th>\n",
       "      <th>CS</th>\n",
       "      <th>KQ</th>\n",
       "      <th>AR</th>\n",
       "      <th>SL</th>\n",
       "      <th>FG</th>\n",
       "      <th>WB</th>\n",
       "      <th>PF</th>\n",
       "      <th>WH</th>\n",
       "      <th>SQ</th>\n",
       "      <th>WN</th>\n",
       "      <th>BH</th>\n",
       "      <th>PH</th>\n",
       "      <th>LB</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>inlierLabel</th>\n",
       "      <th>class_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.058750</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>06_DH1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.048750</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.264583</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.071250</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>07_DH1_2</td>\n",
       "      <td>-1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.042917</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.062917</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.058750</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>08_DH1_3</td>\n",
       "      <td>-1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.090833</td>\n",
       "      <td>0.033750</td>\n",
       "      <td>0.305833</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.052917</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>09_DH2_1</td>\n",
       "      <td>1</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>0.442917</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.188333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.049167</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>10_DH2_2</td>\n",
       "      <td>1</td>\n",
       "      <td>WW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_number        FH        ER        WW        TC        CS        KQ  \\\n",
       "0             9  0.041667  0.035000  0.177083  0.020000  0.003750  0.005833   \n",
       "1             9  0.048750  0.034583  0.264583  0.009583  0.002500  0.064583   \n",
       "2             9  0.048333  0.042917  0.253333  0.008750  0.002083  0.062917   \n",
       "3             9  0.090833  0.033750  0.305833  0.010000  0.003333  0.013750   \n",
       "4             2  0.104167  0.035417  0.442917  0.018750  0.014167  0.018333   \n",
       "\n",
       "         AR        SL        FG        WB   PF        WH        SQ        WN  \\\n",
       "0  0.000000  0.052083  0.019583  0.473333  0.0  0.016667  0.058750  0.011667   \n",
       "1  0.000833  0.024583  0.038333  0.317500  0.0  0.020000  0.071250  0.017917   \n",
       "2  0.001667  0.024167  0.039583  0.302500  0.0  0.020833  0.079167  0.020417   \n",
       "3  0.000000  0.036250  0.032083  0.341667  0.0  0.009167  0.037083  0.023333   \n",
       "4  0.000000  0.041250  0.037083  0.188333  0.0  0.008750  0.018333  0.015417   \n",
       "\n",
       "         BH        PH        LB  Analysis  inlierLabel class_predictions  \n",
       "0  0.015833  0.066667  0.002083  06_DH1_1            1                WB  \n",
       "1  0.027500  0.050000  0.007500  07_DH1_2           -1             other  \n",
       "2  0.027500  0.058750  0.007083  08_DH1_3           -1             other  \n",
       "3  0.009167  0.052917  0.000833  09_DH2_1            1                WB  \n",
       "4  0.007083  0.049167  0.000833  10_DH2_2            1                WW  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I think if there is a problem here it's most likely to be in the encodings of the class, perhaps they are not correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    206\n",
       "9    156\n",
       "7      1\n",
       "Name: class_number, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['class_number'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions are stored as a variable into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'results' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions are outputted as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_predictions:\n",
    "    results.to_csv('output_datasets/predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_number</th>\n",
       "      <th>FH</th>\n",
       "      <th>ER</th>\n",
       "      <th>WW</th>\n",
       "      <th>TC</th>\n",
       "      <th>CS</th>\n",
       "      <th>KQ</th>\n",
       "      <th>AR</th>\n",
       "      <th>SL</th>\n",
       "      <th>FG</th>\n",
       "      <th>WB</th>\n",
       "      <th>PF</th>\n",
       "      <th>WH</th>\n",
       "      <th>SQ</th>\n",
       "      <th>WN</th>\n",
       "      <th>BH</th>\n",
       "      <th>PH</th>\n",
       "      <th>LB</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>inlierLabel</th>\n",
       "      <th>class_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.058750</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>06_DH1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.048750</td>\n",
       "      <td>0.034583</td>\n",
       "      <td>0.264583</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.071250</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>07_DH1_2</td>\n",
       "      <td>-1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.042917</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.062917</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.058750</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>08_DH1_3</td>\n",
       "      <td>-1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.090833</td>\n",
       "      <td>0.033750</td>\n",
       "      <td>0.305833</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.052917</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>09_DH2_1</td>\n",
       "      <td>1</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>0.442917</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.014167</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041250</td>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.188333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.049167</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>10_DH2_2</td>\n",
       "      <td>1</td>\n",
       "      <td>WW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_number        FH        ER        WW        TC        CS        KQ  \\\n",
       "0             9  0.041667  0.035000  0.177083  0.020000  0.003750  0.005833   \n",
       "1             9  0.048750  0.034583  0.264583  0.009583  0.002500  0.064583   \n",
       "2             9  0.048333  0.042917  0.253333  0.008750  0.002083  0.062917   \n",
       "3             9  0.090833  0.033750  0.305833  0.010000  0.003333  0.013750   \n",
       "4             2  0.104167  0.035417  0.442917  0.018750  0.014167  0.018333   \n",
       "\n",
       "         AR        SL        FG        WB   PF        WH        SQ        WN  \\\n",
       "0  0.000000  0.052083  0.019583  0.473333  0.0  0.016667  0.058750  0.011667   \n",
       "1  0.000833  0.024583  0.038333  0.317500  0.0  0.020000  0.071250  0.017917   \n",
       "2  0.001667  0.024167  0.039583  0.302500  0.0  0.020833  0.079167  0.020417   \n",
       "3  0.000000  0.036250  0.032083  0.341667  0.0  0.009167  0.037083  0.023333   \n",
       "4  0.000000  0.041250  0.037083  0.188333  0.0  0.008750  0.018333  0.015417   \n",
       "\n",
       "         BH        PH        LB  Analysis  inlierLabel class_predictions  \n",
       "0  0.015833  0.066667  0.002083  06_DH1_1            1                WB  \n",
       "1  0.027500  0.050000  0.007500  07_DH1_2           -1             other  \n",
       "2  0.027500  0.058750  0.007083  08_DH1_3           -1             other  \n",
       "3  0.009167  0.052917  0.000833  09_DH2_1            1                WB  \n",
       "4  0.007083  0.049167  0.000833  10_DH2_2            1                WW  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
