{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules and configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import pickle\n",
    "\n",
    "pd.set_option('max.rows', None)\n",
    "pd.set_option('max.columns', None)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load variables stored by data_preproccessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_data_formodel\n",
    "%store -r test_data\n",
    "%store -r my_data\n",
    "%store -r uniques\n",
    "%store -r best_feats_rfe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configurations\n",
    "* save_plots -> True|False\n",
    "* random_seed_state -> number, sets random state for model and for stratified splits \n",
    "* classify_bedrock_only -> True|False\n",
    "* pickle_model -> True|False, wether model should be serialised and saved\n",
    "* pickle_model_name -> string, name of serialised model\n",
    "* grid_search -> True|False, if set to true then grid search is performed to identify optimum hyperparamaters for model \n",
    "* scale -> True|False if set to True then features scaled to all have mean value 0 and standard deviation 1\n",
    "* pickle_file_path -> string,  filepath for serialised model to be saved to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False\n",
    "random_seed_state = 42\n",
    "classify_bedrock_only = False\n",
    "pickle_model = False\n",
    "pickle_model_name = 'grouped'\n",
    "pickle_file_path = '../../../model'\n",
    "grid_search = False\n",
    "scale = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if only bedrock sites are classified then classes are label encoded, if bedrock sites alone are not being classified then the class sites would have already been label encoded in the 1 data_preproccessing notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classify_bedrock_only:\n",
    "    train_data_formodel['class'], uniques = pd.factorize(train_data_formodel['class'])\n",
    "    train_data_formodel = train_data_formodel[train_data_formodel['Geology']=='Bedrock']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts of instances in all classes before oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    120\n",
       "4     105\n",
       "23    105\n",
       "16    100\n",
       "21     74\n",
       "17     61\n",
       "24     60\n",
       "0      53\n",
       "12     45\n",
       "14     36\n",
       "2      36\n",
       "15     36\n",
       "6      30\n",
       "11     30\n",
       "10     30\n",
       "7      30\n",
       "20     28\n",
       "5      27\n",
       "8      27\n",
       "19     27\n",
       "1      24\n",
       "13     21\n",
       "3      18\n",
       "18     18\n",
       "9      17\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_formodel['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class column is stored as the variable y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train_data_formodel['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variables identified as best by the 2 feature_selection notebook are used as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_feats = train_data_formodel[best_feats_rfe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Li7',\n",
       " 'Nd146',\n",
       " 'Pr141',\n",
       " 'Ce140',\n",
       " 'La139',\n",
       " 'Ba137',\n",
       " 'Cd111',\n",
       " 'Y89',\n",
       " 'Sr88',\n",
       " 'Rb85',\n",
       " 'As75',\n",
       " 'Ge72',\n",
       " 'Ga69',\n",
       " 'Zn68',\n",
       " 'Cu63',\n",
       " 'Ni60',\n",
       " 'Zr90',\n",
       " 'Fe56',\n",
       " 'B11',\n",
       " 'Mg24',\n",
       " 'Si28',\n",
       " 'P31',\n",
       " 'S33',\n",
       " 'K39',\n",
       " 'Al27',\n",
       " 'Sc45',\n",
       " 'Ca42',\n",
       " 'Mn55',\n",
       " 'Cr52',\n",
       " 'V51',\n",
       " 'U238']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feats_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### address class imbalance using synthetic minority oversampling technique (SMOTE) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scale:\n",
    "    my_scaler = StandardScaler()\n",
    "    X = np.array(my_scaler.fit_transform(np.array(train_data_feats)))\n",
    "else:\n",
    "    X = np.array(np.array(train_data_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the dimensions of the class and features are checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1158, 31)\n",
      "(1158,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gri dsearch is done to identify best hyperparamaters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if grid_search:\n",
    "    esti = RandomForestClassifier()\n",
    "\n",
    "\n",
    "    \n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 3000, num = 10)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    min_samples_split = [2, 5, 10, 15]\n",
    "    min_samples_leaf = [1, 2, 4, 8]\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    \n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "    \n",
    "    clf = RandomizedSearchCV(estimator = esti, n_iter=200, param_distributions = random_grid,\n",
    "                              n_jobs=-1, scoring='f1_macro', cv = 3, verbose=3, \n",
    "                              random_state = random_seed_state)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    print(clf.best_params_)\n",
    "    mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best paramaters from the randomised grid search were the following:\n",
    "{'n_estimators': 1755, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': True}\n",
    "\n",
    "randomised grid search took ~18 mins for 600 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if grid_search:\n",
    "    esti = RandomForestClassifier(bootstrap = True, max_features = 'auto')\n",
    "\n",
    "    n_estimators = [1600, 1700, 1800]\n",
    "    max_depth = [80, 100, 120]\n",
    "    min_samples_split = [2, 3, 4]\n",
    "    min_samples_leaf = [1, 2, 3]\n",
    "    \n",
    "    \n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "                  }\n",
    "    \n",
    "    clf = GridSearchCV(estimator = esti, param_grid= random_grid,\n",
    "                              n_jobs=-1, scoring='f1_macro', cv = 3, verbose=3)\n",
    "    clf.fit(X, y)\n",
    "    print(clf.best_params_)\n",
    "    mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best paramters identified by gridsearch were:\n",
    "{'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 1700}\n",
    "\n",
    "so final best paramaters are\n",
    "\n",
    "{'n_estimators': 1700 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': True}\n",
    "\n",
    "it took  7 mins for 243 fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carry out 10-f0ld stratified cross validation, class f1 scores and macro f1 scores with weighted averages are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model:\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No samples will be generated with the provided ratio settings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-311b837e9d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mX_post_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_post_smote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mesti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_post_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_post_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/imblearn/over_sampling/adasyn.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mn_samples_generate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio_nn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 raise ValueError(\"No samples will be generated with the\"\n\u001b[0m\u001b[1;32m    181\u001b[0m                                  \" provided ratio settings.\")\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No samples will be generated with the provided ratio settings."
     ]
    }
   ],
   "source": [
    "esti = RandomForestClassifier(n_estimators=1700, random_state = random_seed_state, n_jobs=-1, \n",
    "                              min_samples_split =  3, min_samples_leaf = 1, max_features = 'auto', \n",
    "                              max_depth = 100, bootstrap =  True)\n",
    "skf = StratifiedKFold(n_splits=10, random_state=random_seed_state)\n",
    "skf.get_n_splits(X, y)\n",
    "class_f1_scores = []\n",
    "macro_f1_scores = []\n",
    "accuracy_scores = []\n",
    "feat_imp =[]\n",
    "f1_dict = {}\n",
    "feat_imp_dict = {}\n",
    "count = 0\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    count = count + 1\n",
    "    print('making model:')\n",
    "    key = 'round' + str(count)\n",
    "    print(count)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_post_smote, y_post_smote = SMOTE(random_state=42).fit_sample(X_train, y_train)\n",
    "    \n",
    "    esti.fit(X_post_smote, y_post_smote)\n",
    "\n",
    "    y_pred = esti.predict(X_test)\n",
    "    class_f1_scores = f1_score(y_test, y_pred, average = None)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    macro_f1_scores.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "    f1_dict[key] = class_f1_scores \n",
    "    feat_imp_dict[key] = esti.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df = pd.DataFrame(data = f1_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in f1_dict:\n",
    "    print(len(f1_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the encodings for the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_formodel['class'].unique())\n",
    "print(list(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df_final = pd.concat([f1_df, pd.Series(uniques)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df_final.rename(columns={0:'class'}, inplace=True)\n",
    "f1_df_final.set_index('class', drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot showing the distribution of class f1 scores from 10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "plot = sns.boxplot(data = f1_df_final.T)\n",
    "plot.set_title('F1 scores for each site', fontdict={'fontsize': 14})\n",
    "plot.set_ylabel('F1 score', fontdict={'fontsize': 11})\n",
    "plot.set_xlabel(\"Bedrock site or superficial site\", fontdict={'fontsize': 11})\n",
    "\n",
    "if save_plots == True:\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('output/site_specific_f1_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(data = f1_df_final.T.median()).to_csv('output/median_class_f1_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot showing the macro F1 score with weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.boxplot(macro_f1_scores)\n",
    "plot.set_title('Average-weighted macro-f1 score', fontdict={'fontsize': 14})\n",
    "plot.set_xlabel(\"F1-score\", fontdict={'fontsize': 11})\n",
    "\n",
    "if save_plots == True:\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('output/macro_f1_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(pd.Series(macro_f1_scores).median()).to_csv('output/median_macro_f1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(macro_f1_scores).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot showing accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat_imp_df = pd.DataFrame(data = feat_imp_dict)\n",
    "feat_imp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat_imp_df_final = pd.concat([feat_imp_df, pd.Series(my_data[my_data.columns.values[9:-1]].columns.values)], axis = 1)\n",
    "feat_imp_df_final.rename(columns = {0:'element'}, inplace = True )\n",
    "feat_imp_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat_imp_df_final.set_index('element', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat_imp_df_final_plot = feat_imp_df_final.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat_imp_df_final_plot\n",
    "\n",
    "elements = feat_imp_df_final_plot.columns.values \n",
    "mean_feature_importance = []\n",
    "for col in list(feat_imp_df_final_plot.columns.values):\n",
    "    mean_feature_importance.append(feat_imp_df_final_plot[col].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_feature_importance_df = pd.concat([pd.Series(elements), pd.Series(mean_feature_importance)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_feature_importance_df.rename(columns={0:'elements', 1:'mean_importance'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_feature_importance_df.sort_values(by='mean_importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ordered_col_names = list(mean_feature_importance_df['elements'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style()\n",
    "sns.set(rc={'figure.figsize':(20,20)})\n",
    "plot = sns.boxplot(data = feat_imp_df_final_plot[ordered_col_names])\n",
    "plot.set_xticklabels(plot.get_xticklabels(),rotation=90, ha = 'left')\n",
    "plot.set_title('Feature (element) importance', fontdict={'fontsize': 20})\n",
    "plot.set_ylabel('Feature importance', fontdict={'fontsize': 15})\n",
    "plot.set_xlabel(\"Element\", fontdict={'fontsize': 15})\n",
    "\n",
    "if save_plots == True:\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('output/feature_importances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model is built for predicting source of artefacts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esti_final = RandomForestClassifier(n_estimators=2000, random_state = random_seed_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esti_final.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pickle_model == True:\n",
    "    pickle.dump(esti_final, open(pickle_file_path+'.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(train_data_formodel['class'].unique())\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_for_identifiers = test_data.copy(deep = True)\n",
    "identifiers =  df_for_identifiers['Analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions are made for the artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = esti_final.predict(np.array(test_data[test_data.columns.values[9:-1]]))\n",
    "\n",
    "y_pred_proba = esti_final.predict_proba(np.array(test_data[test_data.columns.values[9:-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probabilities_df = pd.DataFrame(data = y_pred_proba, columns = uniques)\n",
    "probabilities_df_final = pd.concat([probabilities_df, pd.Series(list(identifiers))], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probabilities_df_final.rename(columns = {0:'identifier'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_pred_df = pd.concat([pd.Series(y_pred), probabilities_df_final], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_pred_df.rename(columns={0:'class_number'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictions are outputted as csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_pred_df.to_csv('output/predictions.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uniques_list = list(uniques)\n",
    "def get_pred_names(row):\n",
    "    return(uniques_list[row['class_number']])\n",
    "final_pred_df['class_predictions'] = final_pred_df.apply(get_pred_names, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
