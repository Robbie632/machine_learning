{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules and configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import pickle\n",
    "\n",
    "pd.set_option('max.rows', None)\n",
    "pd.set_option('max.columns', None)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load variables stored by data_preproccessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_data_formodel\n",
    "%store -r test_data\n",
    "%store -r my_data\n",
    "%store -r uniques\n",
    "%store -r best_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False\n",
    "random_seed_state = 42\n",
    "classify_bedrock_only = False\n",
    "pickle_model = False\n",
    "pickle_model_name = 'grouped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I label encode the class column again because just bedrock is being classified and when class was label encoded in data reproccessing script label encoding was done for both bedrock sites and superficial regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classify_bedrock_only:\n",
    "    train_data_formodel['class'], uniques = pd.factorize(train_data_formodel['class'])\n",
    "    train_data_formodel = train_data_formodel[train_data_formodel['Geology']=='Bedrock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Li7', 'Be9', 'B11', 'Mg24', 'Al27', 'Si28', 'P31', 'S33', 'K39',\n",
       "       'Ca42', 'Sc45', 'Ti47', 'V51', 'Cr52', 'Mn55', 'Fe56', 'Co59',\n",
       "       'Ni60', 'Cu63', 'Zn68', 'Ga69', 'Ge72', 'As75', 'Rb85', 'Sr88',\n",
       "       'Y89', 'Zr90', 'Nb93', 'Mo95', 'Cd111', 'In115', 'Sn118', 'Cs133',\n",
       "       'Ba137', 'La139', 'Ce140', 'Pr141', 'Nd146', 'Sm147', 'Eu153',\n",
       "       'Gd157', 'Tb159', 'Dy163', 'Ho165', 'Er166', 'Tm169', 'Yb172',\n",
       "       'Lu175', 'Hf178', 'Ta181', 'Pb208', 'Th232', 'U238'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_formodel.columns.values[9:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Geology</th>\n",
       "      <th>Province</th>\n",
       "      <th>Region</th>\n",
       "      <th>Site</th>\n",
       "      <th>SubSite</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Band</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Li7</th>\n",
       "      <th>Be9</th>\n",
       "      <th>B11</th>\n",
       "      <th>Mg24</th>\n",
       "      <th>Al27</th>\n",
       "      <th>Si28</th>\n",
       "      <th>P31</th>\n",
       "      <th>S33</th>\n",
       "      <th>K39</th>\n",
       "      <th>Ca42</th>\n",
       "      <th>Sc45</th>\n",
       "      <th>Ti47</th>\n",
       "      <th>V51</th>\n",
       "      <th>Cr52</th>\n",
       "      <th>Mn55</th>\n",
       "      <th>Fe56</th>\n",
       "      <th>Co59</th>\n",
       "      <th>Ni60</th>\n",
       "      <th>Cu63</th>\n",
       "      <th>Zn68</th>\n",
       "      <th>Ga69</th>\n",
       "      <th>Ge72</th>\n",
       "      <th>As75</th>\n",
       "      <th>Rb85</th>\n",
       "      <th>Sr88</th>\n",
       "      <th>Y89</th>\n",
       "      <th>Zr90</th>\n",
       "      <th>Nb93</th>\n",
       "      <th>Mo95</th>\n",
       "      <th>Cd111</th>\n",
       "      <th>In115</th>\n",
       "      <th>Sn118</th>\n",
       "      <th>Cs133</th>\n",
       "      <th>Ba137</th>\n",
       "      <th>La139</th>\n",
       "      <th>Ce140</th>\n",
       "      <th>Pr141</th>\n",
       "      <th>Nd146</th>\n",
       "      <th>Sm147</th>\n",
       "      <th>Eu153</th>\n",
       "      <th>Gd157</th>\n",
       "      <th>Tb159</th>\n",
       "      <th>Dy163</th>\n",
       "      <th>Ho165</th>\n",
       "      <th>Er166</th>\n",
       "      <th>Tm169</th>\n",
       "      <th>Yb172</th>\n",
       "      <th>Lu175</th>\n",
       "      <th>Hf178</th>\n",
       "      <th>Ta181</th>\n",
       "      <th>Pb208</th>\n",
       "      <th>Th232</th>\n",
       "      <th>U238</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>15.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>48.36</td>\n",
       "      <td>154.63</td>\n",
       "      <td>943.71</td>\n",
       "      <td>464944.18</td>\n",
       "      <td>50.28</td>\n",
       "      <td>538.57</td>\n",
       "      <td>455.94</td>\n",
       "      <td>712.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>15.58</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.69</td>\n",
       "      <td>8.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.62</td>\n",
       "      <td>10.82</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>12.94</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>44.77</td>\n",
       "      <td>22.42</td>\n",
       "      <td>1077.11</td>\n",
       "      <td>465010.94</td>\n",
       "      <td>70.91</td>\n",
       "      <td>438.20</td>\n",
       "      <td>387.82</td>\n",
       "      <td>515.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>18.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.01</td>\n",
       "      <td>11.59</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.45</td>\n",
       "      <td>13.22</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12_FH1_1_1</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_1</td>\n",
       "      <td>20.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>44.88</td>\n",
       "      <td>42.70</td>\n",
       "      <td>620.21</td>\n",
       "      <td>465295.41</td>\n",
       "      <td>104.47</td>\n",
       "      <td>372.66</td>\n",
       "      <td>363.71</td>\n",
       "      <td>957.89</td>\n",
       "      <td>0.76</td>\n",
       "      <td>19.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.21</td>\n",
       "      <td>87.99</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.53</td>\n",
       "      <td>11.98</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_FH1_1_2</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_2</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0.73</td>\n",
       "      <td>47.06</td>\n",
       "      <td>162.42</td>\n",
       "      <td>1143.19</td>\n",
       "      <td>465099.89</td>\n",
       "      <td>56367.93</td>\n",
       "      <td>1075.89</td>\n",
       "      <td>547.55</td>\n",
       "      <td>2174.30</td>\n",
       "      <td>0.43</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0.67</td>\n",
       "      <td>152.42</td>\n",
       "      <td>4.84</td>\n",
       "      <td>145.34</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.45</td>\n",
       "      <td>5.02</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>13.16</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14_FH1_1_2</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Northern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FH</td>\n",
       "      <td>FH1</td>\n",
       "      <td>Burnham</td>\n",
       "      <td>FH1</td>\n",
       "      <td>FH1_1_2</td>\n",
       "      <td>17.71</td>\n",
       "      <td>0.32</td>\n",
       "      <td>48.26</td>\n",
       "      <td>33.52</td>\n",
       "      <td>547.22</td>\n",
       "      <td>465027.11</td>\n",
       "      <td>44.44</td>\n",
       "      <td>464.78</td>\n",
       "      <td>278.25</td>\n",
       "      <td>1551.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>11.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.73</td>\n",
       "      <td>25.38</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Analysis  Geology  Province Region Site SubSite Formation Band   Nodule  \\\n",
       "0  10_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "1  11_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "2  12_FH1_1_1  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_1   \n",
       "3  13_FH1_1_2  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_2   \n",
       "4  14_FH1_1_2  Bedrock  Northern    NaN   FH     FH1   Burnham  FH1  FH1_1_2   \n",
       "\n",
       "     Li7   Be9    B11    Mg24     Al27       Si28       P31      S33     K39  \\\n",
       "0  15.63  0.12  48.36  154.63   943.71  464944.18     50.28   538.57  455.94   \n",
       "1  11.50  0.09  44.77   22.42  1077.11  465010.94     70.91   438.20  387.82   \n",
       "2  20.05  0.06  44.88   42.70   620.21  465295.41    104.47   372.66  363.71   \n",
       "3  11.16  0.73  47.06  162.42  1143.19  465099.89  56367.93  1075.89  547.55   \n",
       "4  17.71  0.32  48.26   33.52   547.22  465027.11     44.44   464.78  278.25   \n",
       "\n",
       "      Ca42  Sc45   Ti47   V51    Cr52  Mn55    Fe56  Co59  Ni60  Cu63   Zn68  \\\n",
       "0   712.39  0.42  15.58  0.27    3.30  0.69    8.46  0.05  0.80  1.62  10.82   \n",
       "1   515.24  0.44  18.47  0.29    3.45  1.01   11.59  0.11  0.36  0.53   8.93   \n",
       "2   957.89  0.76  19.89  0.55    3.25  1.21   87.99  0.21  1.68  1.53  11.98   \n",
       "3  2174.30  0.43  42.30  0.67  152.42  4.84  145.34  0.30  2.45  5.02  17.15   \n",
       "4  1551.63  0.71  11.18  0.27    2.56  1.73   25.38  0.05  0.80  0.55   9.80   \n",
       "\n",
       "   Ga69  Ge72  As75  Rb85   Sr88   Y89  Zr90  Nb93  Mo95  Cd111  In115  Sn118  \\\n",
       "0  0.25  1.22  0.16  0.43  12.94  0.88  1.51  0.09  0.05   0.02   0.00   0.05   \n",
       "1  0.34  0.85  0.10  0.45  13.22  0.95  1.74  0.07  0.01   0.02   0.00   0.04   \n",
       "2  0.25  1.71  0.13  0.43   8.52  0.87  0.93  0.10  0.02   0.02   0.00   0.05   \n",
       "3  0.35  2.13  0.84  0.76  13.16  0.97  2.00  0.10  0.29   0.18   0.01   0.78   \n",
       "4  0.41  1.41  0.12  0.28   9.90  0.90  0.90  0.08  0.04   0.10   0.00   0.09   \n",
       "\n",
       "   Cs133  Ba137  La139  Ce140  Pr141  Nd146  Sm147  Eu153  Gd157  Tb159  \\\n",
       "0   0.01   6.54   0.84   0.95   0.23   0.87   0.16   0.04   0.16   0.02   \n",
       "1   0.02   8.04   0.92   1.01   0.23   0.98   0.18   0.04   0.18   0.02   \n",
       "2   0.01   3.13   0.90   1.08   0.26   0.84   0.15   0.04   0.19   0.02   \n",
       "3   0.04   8.74   0.93   0.95   0.21   0.75   0.13   0.04   0.25   0.02   \n",
       "4   0.01   2.74   0.97   1.09   0.27   1.00   0.17   0.04   0.19   0.02   \n",
       "\n",
       "   Dy163  Ho165  Er166  Tm169  Yb172  Lu175  Hf178  Ta181  Pb208  Th232  U238  \\\n",
       "0   0.11   0.03   0.06   0.01   0.02   0.00   0.04   0.01   0.24   0.07  0.05   \n",
       "1   0.13   0.03   0.06   0.01   0.04   0.01   0.05   0.00   0.07   0.08  0.04   \n",
       "2   0.14   0.02   0.07   0.01   0.06   0.00   0.02   0.01   0.46   0.05  0.05   \n",
       "3   0.09   0.03   0.05   0.00   0.03   0.00   0.08   0.00   0.64   0.05  0.03   \n",
       "4   0.15   0.03   0.05   0.01   0.05   0.01   0.02   0.01   0.59   0.06  0.09   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_formodel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train_data_formodel['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_feats = train_data_formodel[train_data_formodel.columns.values[9:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1243, 53)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn feature data and class to be predicited into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_data_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1243, 53)\n",
      "(1243,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carry out 10-f0ld stratified cross validation, class f1 scores and macro f1 scores with weighted averages are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model:\n",
      "1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ClassifierMixin' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b199c337d0df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mclass_f1_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ClassifierMixin' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "skf = StratifiedKFold(n_splits=10, random_state=random_seed_state)\n",
    "skf.get_n_splits(X, y)\n",
    "class_f1_scores = []\n",
    "macro_f1_scores = []\n",
    "accuracy_scores = []\n",
    "feat_imp =[]\n",
    "f1_dict = {}\n",
    "feat_imp_dict = {}\n",
    "count = 0\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    count = count + 1\n",
    "    print('making model:')\n",
    "    key = 'round' + str(count)\n",
    "    print(count)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    class_f1_scores = f1_score(y_test, y_pred, average = None)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    macro_f1_scores.append(f1_score(y_test, y_pred, average = 'weighted'))\n",
    "    f1_dict[key] = class_f1_scores \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df = pd.DataFrame(data = f1_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in f1_dict:\n",
    "    print(len(f1_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the encodings for the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_formodel['class'].unique())\n",
    "print(list(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df_final = pd.concat([f1_df, pd.Series(uniques)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df_final.rename(columns={0:'class'}, inplace=True)\n",
    "f1_df_final.set_index('class', drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot showing the distribution of class f1 scores from 10 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "plot = sns.boxplot(data = f1_df_final.T)\n",
    "plot.set_title('F1 scores for each site', fontdict={'fontsize': 14})\n",
    "plot.set_ylabel('F1 score', fontdict={'fontsize': 11})\n",
    "plot.set_xlabel(\"Bedrock site or superficial site\", fontdict={'fontsize': 11})\n",
    "\n",
    "if save_plots == True:\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('output/site_specific_f1_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = f1_df_final.T.median()).to_csv('output/median_class_f1_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot showing the macro F1 score with weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.boxplot(macro_f1_scores)\n",
    "plot.set_title('Average-weighted macro-f1 score', fontdict={'fontsize': 14})\n",
    "plot.set_xlabel(\"F1-score\", fontdict={'fontsize': 11})\n",
    "\n",
    "if save_plots == True:\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('output/macro_f1_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(pd.Series(macro_f1_scores).median()).to_csv('output/median_macro_f1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot showing accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df = pd.DataFrame(data = feat_imp_dict)\n",
    "feat_imp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_final = pd.concat([feat_imp_df, pd.Series(my_data[my_data.columns.values[9:-1]].columns.values)], axis = 1)\n",
    "feat_imp_df_final.rename(columns = {0:'element'}, inplace = True )\n",
    "feat_imp_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_final.set_index('element', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_final_plot = feat_imp_df_final.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp_df_final_plot\n",
    "\n",
    "elements = feat_imp_df_final_plot.columns.values \n",
    "mean_feature_importance = []\n",
    "for col in list(feat_imp_df_final_plot.columns.values):\n",
    "    mean_feature_importance.append(feat_imp_df_final_plot[col].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_feature_importance_df = pd.concat([pd.Series(elements), pd.Series(mean_feature_importance)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_feature_importance_df.rename(columns={0:'elements', 1:'mean_importance'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_feature_importance_df.sort_values(by='mean_importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_col_names = list(mean_feature_importance_df['elements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style()\n",
    "sns.set(rc={'figure.figsize':(20,20)})\n",
    "plot = sns.boxplot(data = feat_imp_df_final_plot[ordered_col_names])\n",
    "plot.set_xticklabels(plot.get_xticklabels(),rotation=90, ha = 'left')\n",
    "plot.set_title('Feature (element) importance', fontdict={'fontsize': 20})\n",
    "plot.set_ylabel('Feature importance', fontdict={'fontsize': 15})\n",
    "plot.set_xlabel(\"Element\", fontdict={'fontsize': 15})\n",
    "\n",
    "if save_plots == True:\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('output/feature_importances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model is built for predicting source of artefacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_final = RandomForestClassifier(n_estimators=2000, random_state = random_seed_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_final.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pickle_model == True:\n",
    "    pickle.dump(RFC_final, open('models/' + pickle_model_name + '_' + 'rfc_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_formodel['class'].unique())\n",
    "print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_identifiers = test_data.copy(deep = True)\n",
    "identifiers =  df_for_identifiers['Analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions are made for the artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RFC_final.predict(np.array(test_data[test_data.columns.values[9:-1]]))\n",
    "\n",
    "y_pred_proba = RFC_final.predict_proba(np.array(test_data[test_data.columns.values[9:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_df = pd.DataFrame(data = y_pred_proba, columns = uniques)\n",
    "probabilities_df_final = pd.concat([probabilities_df, pd.Series(list(identifiers))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_df_final.rename(columns = {0:'identifier'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df = pd.concat([pd.Series(y_pred), probabilities_df_final], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df.rename(columns={0:'class_number'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df.to_csv('output/predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_list = list(uniques)\n",
    "def get_pred_names(row):\n",
    "    return(uniques_list[row['class_number']])\n",
    "final_pred_df['class_predictions'] = final_pred_df.apply(get_pred_names, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_pred_df_modal = final_pred_df.groupby(by = 'class_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
