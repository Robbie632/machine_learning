{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules and configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "pd.set_option('max.rows', None)\n",
    "pd.set_option('max.columns', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load variables stored by data_preproccessing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_data_formodel\n",
    "%store -r test_data\n",
    "%store -r my_data\n",
    "%store -r uniques\n",
    "%store -r best_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configurations\n",
    "* save_plots -> boolean\n",
    "* random_seed_state -> number, sets random state for model and for stratified splits \n",
    "* pickle_model -> True|False, wether model should be serialised and saved\n",
    "* pickle_model_name -> string, name of serialised model\n",
    "* scale -> True|False if set to True then features scaled to all have mean value 0 and standard deviation 1\n",
    "* pickle_file_path -> string,  filepath for serialised model to be saved to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False\n",
    "random_seed_state = 42\n",
    "pickle_model = False\n",
    "pickle_model_name = 'grouped'\n",
    "pickle_file_path = '../../../model'\n",
    "scale = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts of instances in all classes before oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     105\n",
       "17    100\n",
       "18     61\n",
       "0      53\n",
       "10     47\n",
       "13     45\n",
       "15     36\n",
       "16     36\n",
       "2      36\n",
       "12     30\n",
       "11     30\n",
       "8      30\n",
       "7      30\n",
       "5      30\n",
       "6      27\n",
       "9      27\n",
       "1      24\n",
       "14     21\n",
       "3      18\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_formodel['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The class column is stored as the variable y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data_formodel['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The variables identified as best by feature selection are used as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_feats = train_data_formodel[best_feats]\n",
    "test_data_feats = test_data[best_feats]\n",
    "test_data_identifiers = test_data['Analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features are standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scale:\n",
    "    my_scaler = StandardScaler()\n",
    "    X_test = np.array(my_scaler.fit_transform(test_data_feats))\n",
    "    X_train = np.array(my_scaler.fit_transform(train_data_feats))\n",
    "else:\n",
    "    X_test = np.array(test_data_feats)\n",
    "    X_train = np.array(train_data_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the dimensions of the class and features are checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786, 25)\n",
      "(363, 25)\n",
      "(786,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor model is fitted on data that will be used for training the final classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(novelty=True, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print details of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalOutlierFactor(algorithm='auto', contamination='legacy', leaf_size=30,\n",
      "          metric='minkowski', metric_params=None, n_jobs=None,\n",
      "          n_neighbors=20, novelty=True, p=2)\n"
     ]
    }
   ],
   "source": [
    "print(lof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/lof.py:236: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LocalOutlierFactor(algorithm='auto', contamination='legacy', leaf_size=30,\n",
       "          metric='minkowski', metric_params=None, n_jobs=None,\n",
       "          n_neighbors=20, novelty=True, p=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lof.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor model predicts whether the artefact samples are inliers or outliers encoded with 1 and -1 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lof.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    182\n",
       " 1    181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nInliers = list(pd.Series(predictions).value_counts())[0]\n",
    "nOutliers = list(pd.Series(predictions).value_counts())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 182 inliers and 181 outliers, so the proportion of inliers is 0.5013774104683195\n"
     ]
    }
   ],
   "source": [
    "print('there are {0} inliers and {1} outliers, so the proportion of inliers is {2}'.format(nInliers, nOutliers, (nInliers)/(X_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column encoding inlier status is added to artefact-sample dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(data = X_test, columns = test_data_feats.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_labeled_df = pd.concat([test_data_identifiers.reset_index(drop = True), X_test_df, pd.Series(predictions)], axis =1).rename(columns = {0:'inlierLabel'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Li7</th>\n",
       "      <th>Nd146</th>\n",
       "      <th>Pr141</th>\n",
       "      <th>La139</th>\n",
       "      <th>Ba137</th>\n",
       "      <th>Y89</th>\n",
       "      <th>Sr88</th>\n",
       "      <th>Rb85</th>\n",
       "      <th>As75</th>\n",
       "      <th>Ge72</th>\n",
       "      <th>Ga69</th>\n",
       "      <th>Zn68</th>\n",
       "      <th>Cu63</th>\n",
       "      <th>Fe56</th>\n",
       "      <th>Zr90</th>\n",
       "      <th>Cr52</th>\n",
       "      <th>B11</th>\n",
       "      <th>Mg24</th>\n",
       "      <th>Mn55</th>\n",
       "      <th>P31</th>\n",
       "      <th>S33</th>\n",
       "      <th>K39</th>\n",
       "      <th>Al27</th>\n",
       "      <th>Sc45</th>\n",
       "      <th>V51</th>\n",
       "      <th>inlierLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06_DH1_1</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.69</td>\n",
       "      <td>20.75</td>\n",
       "      <td>11.14</td>\n",
       "      <td>35.38</td>\n",
       "      <td>1.43</td>\n",
       "      <td>5.18</td>\n",
       "      <td>93.21</td>\n",
       "      <td>27.83</td>\n",
       "      <td>3.27</td>\n",
       "      <td>35.07</td>\n",
       "      <td>806.55</td>\n",
       "      <td>443.100000</td>\n",
       "      <td>635.240000</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07_DH1_2</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>7.51</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.77000</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.86</td>\n",
       "      <td>18.15</td>\n",
       "      <td>8.64</td>\n",
       "      <td>49.23</td>\n",
       "      <td>1.47</td>\n",
       "      <td>5.43</td>\n",
       "      <td>95.19</td>\n",
       "      <td>27.99</td>\n",
       "      <td>2.30</td>\n",
       "      <td>31.65</td>\n",
       "      <td>807.55</td>\n",
       "      <td>442.100000</td>\n",
       "      <td>639.090000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08_DH1_3</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.71000</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.79</td>\n",
       "      <td>17.54</td>\n",
       "      <td>3.44</td>\n",
       "      <td>16.46</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2.61</td>\n",
       "      <td>93.63</td>\n",
       "      <td>26.43</td>\n",
       "      <td>1.40</td>\n",
       "      <td>25.43</td>\n",
       "      <td>837.73</td>\n",
       "      <td>444.280000</td>\n",
       "      <td>670.480000</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09_DH2_1</td>\n",
       "      <td>18.47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.23</td>\n",
       "      <td>12.48</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.62000</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.75</td>\n",
       "      <td>14.33</td>\n",
       "      <td>1.10</td>\n",
       "      <td>16.76</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.87</td>\n",
       "      <td>63.80</td>\n",
       "      <td>31.98</td>\n",
       "      <td>1.09</td>\n",
       "      <td>24.63</td>\n",
       "      <td>750.62</td>\n",
       "      <td>383.353245</td>\n",
       "      <td>620.245528</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_DH2_2</td>\n",
       "      <td>19.98</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.48</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.73562</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.76</td>\n",
       "      <td>14.59</td>\n",
       "      <td>1.23</td>\n",
       "      <td>62.16</td>\n",
       "      <td>1.99</td>\n",
       "      <td>5.92</td>\n",
       "      <td>60.96</td>\n",
       "      <td>44.95</td>\n",
       "      <td>1.26</td>\n",
       "      <td>22.59</td>\n",
       "      <td>796.21</td>\n",
       "      <td>383.353245</td>\n",
       "      <td>620.245528</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Analysis    Li7  Nd146  Pr141  La139  Ba137   Y89  Sr88     Rb85  As75  \\\n",
       "0  06_DH1_1   2.79   0.34   0.07   0.18   5.95  0.21  2.00  0.72000  0.44   \n",
       "1  07_DH1_2   2.37   0.24   0.06   0.19   7.51  0.21  1.84  0.77000  0.44   \n",
       "2  08_DH1_3   2.46   0.08   0.03   0.11   4.40  0.13  1.93  0.71000  0.42   \n",
       "3  09_DH2_1  18.47   0.25   0.06   0.23  12.48  0.20  4.29  1.62000  0.46   \n",
       "4  10_DH2_2  19.98   0.51   0.12   0.48  14.40  0.27  4.44  0.73562  0.43   \n",
       "\n",
       "   Ge72  Ga69   Zn68   Cu63   Fe56  Zr90  Cr52    B11   Mg24  Mn55    P31  \\\n",
       "0  1.37  0.69  20.75  11.14  35.38  1.43  5.18  93.21  27.83  3.27  35.07   \n",
       "1  1.93  0.86  18.15   8.64  49.23  1.47  5.43  95.19  27.99  2.30  31.65   \n",
       "2  2.14  0.79  17.54   3.44  16.46  1.16  2.61  93.63  26.43  1.40  25.43   \n",
       "3  1.59  0.75  14.33   1.10  16.76  1.45  2.87  63.80  31.98  1.09  24.63   \n",
       "4  0.81  0.76  14.59   1.23  62.16  1.99  5.92  60.96  44.95  1.26  22.59   \n",
       "\n",
       "      S33         K39        Al27  Sc45   V51  inlierLabel  \n",
       "0  806.55  443.100000  635.240000  1.08  0.51            1  \n",
       "1  807.55  442.100000  639.090000  1.09  0.60            1  \n",
       "2  837.73  444.280000  670.480000  1.17  0.62            1  \n",
       "3  750.62  383.353245  620.245528  1.19  1.52            1  \n",
       "4  796.21  383.353245  620.245528  1.22  2.44            1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_labeled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_test_labeled_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store X_test_labeled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
