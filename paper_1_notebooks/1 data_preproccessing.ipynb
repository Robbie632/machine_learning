{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preproccessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import modules and configure notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from functions.preproccessing import clean_columns, split_data, replace_outliers \n",
    "\n",
    "pd.set_option('max.rows', None)\n",
    "pd.set_option('max.columns', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_and_dependencies.config import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(data_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0c81f8da0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3650.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(50.7,8.27)})\n",
    "sns.countplot(my_data['Site'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         FH\n",
       "1         FH\n",
       "2         FH\n",
       "3         FH\n",
       "4         FH\n",
       "5         FH\n",
       "6         FH\n",
       "7         FH\n",
       "8         FH\n",
       "9         FH\n",
       "10        FH\n",
       "11        FH\n",
       "12        FH\n",
       "13        FH\n",
       "14        FH\n",
       "15        FH\n",
       "16        FH\n",
       "17        FH\n",
       "19        FH\n",
       "20        FH\n",
       "21        FH\n",
       "22        FH\n",
       "23        FH\n",
       "24        FH\n",
       "25        FH\n",
       "26        FH\n",
       "27        FH\n",
       "28        FH\n",
       "29        FH\n",
       "30        FH\n",
       "31        FH\n",
       "32        FH\n",
       "33        FH\n",
       "34        FH\n",
       "35        FH\n",
       "36        FH\n",
       "37        FH\n",
       "38        FH\n",
       "39        FH\n",
       "40        FH\n",
       "41        FH\n",
       "42        FH\n",
       "43        FH\n",
       "44        FH\n",
       "45        FH\n",
       "46        FH\n",
       "47        FH\n",
       "48        FH\n",
       "49        FH\n",
       "50        FH\n",
       "51        FH\n",
       "52        FH\n",
       "53        FH\n",
       "54        ER\n",
       "56        ER\n",
       "57        ER\n",
       "58        ER\n",
       "59        ER\n",
       "61        ER\n",
       "62        ER\n",
       "63        ER\n",
       "64        ER\n",
       "65        ER\n",
       "66        ER\n",
       "67        ER\n",
       "68        ER\n",
       "69        ER\n",
       "70        ER\n",
       "71        ER\n",
       "73        ER\n",
       "74        ER\n",
       "75        ER\n",
       "76        ER\n",
       "77        ER\n",
       "78        ER\n",
       "79        ER\n",
       "80        ER\n",
       "81        WW\n",
       "82        WW\n",
       "83        WW\n",
       "84        WW\n",
       "85        WW\n",
       "86        WW\n",
       "87        WW\n",
       "88        WW\n",
       "89        WW\n",
       "90        WW\n",
       "91        WW\n",
       "92        WW\n",
       "93        WW\n",
       "94        WW\n",
       "95        WW\n",
       "96        WW\n",
       "97        WW\n",
       "98        WW\n",
       "99        WW\n",
       "100       WW\n",
       "101       WW\n",
       "102       WW\n",
       "103       WW\n",
       "104       WW\n",
       "105       WW\n",
       "106       WW\n",
       "107       WW\n",
       "108       WW\n",
       "109       WW\n",
       "110       WW\n",
       "111       WW\n",
       "112       WW\n",
       "113       WW\n",
       "114       WW\n",
       "115       WW\n",
       "116       WW\n",
       "117       TC\n",
       "118       TC\n",
       "119       TC\n",
       "120       TC\n",
       "121       TC\n",
       "122       TC\n",
       "123       TC\n",
       "124       TC\n",
       "125       TC\n",
       "126       TC\n",
       "127       TC\n",
       "128       TC\n",
       "129       TC\n",
       "130       TC\n",
       "131       TC\n",
       "132       TC\n",
       "133       TC\n",
       "134       TC\n",
       "135       CS\n",
       "136       CS\n",
       "137       CS\n",
       "138       CS\n",
       "139       CS\n",
       "140       CS\n",
       "141       CS\n",
       "142       CS\n",
       "143       CS\n",
       "144       CS\n",
       "145       CS\n",
       "146       CS\n",
       "147       CS\n",
       "148       CS\n",
       "149       CS\n",
       "150       CS\n",
       "151       CS\n",
       "152       CS\n",
       "153       CS\n",
       "154       CS\n",
       "155       CS\n",
       "156       CS\n",
       "157       CS\n",
       "158       CS\n",
       "159       CS\n",
       "160       CS\n",
       "161       CS\n",
       "162       CS\n",
       "163       CS\n",
       "164       CS\n",
       "165       CS\n",
       "166       CS\n",
       "167       CS\n",
       "168       CS\n",
       "169       CS\n",
       "170       CS\n",
       "171       CS\n",
       "172       CS\n",
       "173       CS\n",
       "174       CS\n",
       "175       CS\n",
       "176       CS\n",
       "177       CS\n",
       "178       CS\n",
       "179       CS\n",
       "180       CS\n",
       "181       CS\n",
       "182       CS\n",
       "183       CS\n",
       "184       CS\n",
       "185       CS\n",
       "186       CS\n",
       "187       CS\n",
       "188       CS\n",
       "189       CS\n",
       "190       CS\n",
       "191       CS\n",
       "192       CS\n",
       "193       CS\n",
       "194       CS\n",
       "195       CS\n",
       "196       CS\n",
       "197       CS\n",
       "198       CS\n",
       "199       CS\n",
       "200       CS\n",
       "201       CS\n",
       "202       CS\n",
       "203       CS\n",
       "204       CS\n",
       "205       CS\n",
       "206       CS\n",
       "207       CS\n",
       "208       CS\n",
       "209       CS\n",
       "210       CS\n",
       "211       CS\n",
       "212       CS\n",
       "213       CS\n",
       "214       CS\n",
       "215       CS\n",
       "216       CS\n",
       "217       CS\n",
       "218       CS\n",
       "219       CS\n",
       "220       CS\n",
       "221       CS\n",
       "222       CS\n",
       "223       CS\n",
       "224       CS\n",
       "225       CS\n",
       "226       CS\n",
       "227       CS\n",
       "228       CS\n",
       "229       CS\n",
       "230       CS\n",
       "231       CS\n",
       "232       CS\n",
       "233       CS\n",
       "234       CS\n",
       "235       CS\n",
       "236       CS\n",
       "237       CS\n",
       "238       CS\n",
       "239       CS\n",
       "270       KQ\n",
       "271       KQ\n",
       "272       KQ\n",
       "273       KQ\n",
       "274       KQ\n",
       "275       KQ\n",
       "276       KQ\n",
       "277       KQ\n",
       "278       KQ\n",
       "279       KQ\n",
       "280       KQ\n",
       "281       KQ\n",
       "282       KQ\n",
       "283       KQ\n",
       "284       KQ\n",
       "285       KQ\n",
       "286       KQ\n",
       "287       KQ\n",
       "288       KQ\n",
       "289       KQ\n",
       "290       KQ\n",
       "291       KQ\n",
       "292       KQ\n",
       "293       KQ\n",
       "294       KQ\n",
       "295       KQ\n",
       "296       KQ\n",
       "297       AR\n",
       "298       AR\n",
       "299       AR\n",
       "300       AR\n",
       "301       AR\n",
       "302       AR\n",
       "303       AR\n",
       "304       AR\n",
       "305       AR\n",
       "306       AR\n",
       "307       AR\n",
       "308       AR\n",
       "309       AR\n",
       "310       AR\n",
       "311       AR\n",
       "312       AR\n",
       "313       AR\n",
       "314       AR\n",
       "315       AR\n",
       "316       AR\n",
       "317       AR\n",
       "318       AR\n",
       "319       AR\n",
       "320       AR\n",
       "321       AR\n",
       "322       AR\n",
       "323       AR\n",
       "324       AR\n",
       "325       AR\n",
       "326       AR\n",
       "327       SL\n",
       "328       SL\n",
       "329       SL\n",
       "330       SL\n",
       "331       SL\n",
       "332       SL\n",
       "333       SL\n",
       "334       SL\n",
       "335       SL\n",
       "336       SL\n",
       "337       SL\n",
       "338       SL\n",
       "339       SL\n",
       "340       SL\n",
       "341       SL\n",
       "342       SL\n",
       "343       SL\n",
       "344       SL\n",
       "345       SL\n",
       "346       SL\n",
       "347       SL\n",
       "348       SL\n",
       "349       SL\n",
       "350       SL\n",
       "351       SL\n",
       "352       SL\n",
       "353       SL\n",
       "354       SL\n",
       "355       SL\n",
       "356       SL\n",
       "357       FG\n",
       "358       FG\n",
       "359       FG\n",
       "360       FG\n",
       "361       FG\n",
       "362       FG\n",
       "363       FG\n",
       "364       FG\n",
       "365       FG\n",
       "366       FG\n",
       "367       FG\n",
       "368       FG\n",
       "369       FG\n",
       "370       FG\n",
       "371       FG\n",
       "372       FG\n",
       "373       FG\n",
       "374       FG\n",
       "375       FG\n",
       "376       FG\n",
       "377       FG\n",
       "378       FG\n",
       "379       FG\n",
       "380       FG\n",
       "381       FG\n",
       "382       FG\n",
       "383       FG\n",
       "385       WB\n",
       "386       WB\n",
       "387       WB\n",
       "388       WB\n",
       "389       WB\n",
       "390       WB\n",
       "391       WB\n",
       "392       WB\n",
       "393       WB\n",
       "394       WB\n",
       "395       WB\n",
       "396       WB\n",
       "397       WB\n",
       "398       WB\n",
       "399       WB\n",
       "400       WB\n",
       "401       WB\n",
       "432       PF\n",
       "433       PF\n",
       "434       PF\n",
       "435       PF\n",
       "436       PF\n",
       "437       PF\n",
       "438       PF\n",
       "439       PF\n",
       "440       PF\n",
       "441       PF\n",
       "442       PF\n",
       "443       PF\n",
       "444       PF\n",
       "445       PF\n",
       "446       PF\n",
       "447       PF\n",
       "448       PF\n",
       "449       PF\n",
       "450       PF\n",
       "451       PF\n",
       "452       PF\n",
       "453       PF\n",
       "454       PF\n",
       "455       PF\n",
       "456       PF\n",
       "457       PF\n",
       "458       PF\n",
       "459       PF\n",
       "460       PF\n",
       "461       PF\n",
       "492       WH\n",
       "493       WH\n",
       "494       WH\n",
       "495       WH\n",
       "496       WH\n",
       "497       WH\n",
       "498       WH\n",
       "499       WH\n",
       "500       WH\n",
       "501       WH\n",
       "502       WH\n",
       "503       WH\n",
       "504       WH\n",
       "505       WH\n",
       "506       WH\n",
       "507       WH\n",
       "508       WH\n",
       "509       WH\n",
       "510       WH\n",
       "511       WH\n",
       "512       WH\n",
       "513       WH\n",
       "514       WH\n",
       "515       WH\n",
       "516       WH\n",
       "517       WH\n",
       "518       WH\n",
       "519       WH\n",
       "520       WH\n",
       "521       WH\n",
       "522       WH\n",
       "523       WH\n",
       "524       WH\n",
       "525       WH\n",
       "526       WH\n",
       "527       WH\n",
       "528       WH\n",
       "529       WH\n",
       "530       WH\n",
       "531       WH\n",
       "532       WH\n",
       "533       WH\n",
       "534       WH\n",
       "535       WH\n",
       "536       WH\n",
       "537       SQ\n",
       "538       SQ\n",
       "539       SQ\n",
       "540       SQ\n",
       "541       SQ\n",
       "542       SQ\n",
       "543       SQ\n",
       "544       SQ\n",
       "545       SQ\n",
       "546       SQ\n",
       "547       SQ\n",
       "548       SQ\n",
       "549       SQ\n",
       "550       SQ\n",
       "551       SQ\n",
       "552       SQ\n",
       "553       SQ\n",
       "554       SQ\n",
       "555       SQ\n",
       "556       SQ\n",
       "557       SQ\n",
       "573       WN\n",
       "574       WN\n",
       "575       WN\n",
       "576       WN\n",
       "577       WN\n",
       "578       WN\n",
       "579       WN\n",
       "580       WN\n",
       "581       WN\n",
       "582       WN\n",
       "583       WN\n",
       "584       WN\n",
       "585       WN\n",
       "586       WN\n",
       "587       WN\n",
       "588       WN\n",
       "589       WN\n",
       "590       WN\n",
       "591       WN\n",
       "592       WN\n",
       "593       WN\n",
       "594       WN\n",
       "595       WN\n",
       "596       WN\n",
       "597       WN\n",
       "598       WN\n",
       "599       WN\n",
       "600       WN\n",
       "601       WN\n",
       "602       WN\n",
       "603       WN\n",
       "604       WN\n",
       "605       WN\n",
       "606       WN\n",
       "607       WN\n",
       "608       WN\n",
       "609       BH\n",
       "610       BH\n",
       "611       BH\n",
       "612       BH\n",
       "613       BH\n",
       "614       BH\n",
       "615       BH\n",
       "616       BH\n",
       "617       BH\n",
       "618       BH\n",
       "619       BH\n",
       "620       BH\n",
       "621       BH\n",
       "622       BH\n",
       "623       BH\n",
       "624       BH\n",
       "625       BH\n",
       "626       BH\n",
       "627       BH\n",
       "628       BH\n",
       "629       BH\n",
       "630       BH\n",
       "631       BH\n",
       "632       BH\n",
       "633       BH\n",
       "634       BH\n",
       "635       BH\n",
       "636       BH\n",
       "637       BH\n",
       "638       BH\n",
       "639       BH\n",
       "640       BH\n",
       "641       BH\n",
       "642       BH\n",
       "643       BH\n",
       "644       BH\n",
       "645       PH\n",
       "646       PH\n",
       "647       PH\n",
       "648       PH\n",
       "649       PH\n",
       "650       PH\n",
       "651       PH\n",
       "652       PH\n",
       "653       PH\n",
       "654       PH\n",
       "655       PH\n",
       "656       PH\n",
       "657       PH\n",
       "658       PH\n",
       "659       PH\n",
       "660       PH\n",
       "661       PH\n",
       "662       PH\n",
       "663       PH\n",
       "664       PH\n",
       "665       PH\n",
       "666       PH\n",
       "667       PH\n",
       "668       PH\n",
       "669       PH\n",
       "670       PH\n",
       "671       PH\n",
       "672       PH\n",
       "673       PH\n",
       "674       PH\n",
       "675       PH\n",
       "676       PH\n",
       "677       PH\n",
       "678       PH\n",
       "679       PH\n",
       "680       PH\n",
       "681       PH\n",
       "682       PH\n",
       "683       PH\n",
       "684       PH\n",
       "685       PH\n",
       "686       PH\n",
       "687       PH\n",
       "688       PH\n",
       "689       PH\n",
       "690       PH\n",
       "691       PH\n",
       "692       PH\n",
       "693       PH\n",
       "694       PH\n",
       "695       PH\n",
       "696       PH\n",
       "697       PH\n",
       "698       PH\n",
       "699       PH\n",
       "700       PH\n",
       "701       PH\n",
       "702       PH\n",
       "703       PH\n",
       "704       PH\n",
       "705       PH\n",
       "706       PH\n",
       "707       PH\n",
       "708       PH\n",
       "709       PH\n",
       "710       PH\n",
       "711       PH\n",
       "712       PH\n",
       "713       PH\n",
       "714       PH\n",
       "715       PH\n",
       "716       PH\n",
       "717       PH\n",
       "718       PH\n",
       "719       PH\n",
       "720       PH\n",
       "721       PH\n",
       "723       PH\n",
       "724       PH\n",
       "725       PH\n",
       "726       PH\n",
       "727       PH\n",
       "728       PH\n",
       "729       PH\n",
       "730       PH\n",
       "731       PH\n",
       "732       PH\n",
       "733       PH\n",
       "734       PH\n",
       "735       PH\n",
       "736       PH\n",
       "737       PH\n",
       "738       PH\n",
       "739       PH\n",
       "740       PH\n",
       "741       PH\n",
       "742       PH\n",
       "743       PH\n",
       "744       PH\n",
       "745       PH\n",
       "747       LB\n",
       "748       LB\n",
       "749       LB\n",
       "750       LB\n",
       "751       LB\n",
       "752       LB\n",
       "753       LB\n",
       "754       LB\n",
       "755       LB\n",
       "756       LB\n",
       "757       LB\n",
       "758       LB\n",
       "759       LB\n",
       "760       LB\n",
       "761       LB\n",
       "762       LB\n",
       "763       LB\n",
       "764       LB\n",
       "765       LB\n",
       "766       LB\n",
       "767       LB\n",
       "768       LB\n",
       "769       LB\n",
       "770       LB\n",
       "771       LB\n",
       "772       LB\n",
       "773       LB\n",
       "774       LB\n",
       "775       LB\n",
       "776       LB\n",
       "777       LB\n",
       "778       LB\n",
       "779       LB\n",
       "780       LB\n",
       "781       LB\n",
       "782       LB\n",
       "783       LB\n",
       "784       LB\n",
       "785       LB\n",
       "786       LB\n",
       "787       LB\n",
       "788       LB\n",
       "789       LB\n",
       "790       LB\n",
       "791       LB\n",
       "792       LB\n",
       "793       LB\n",
       "794       LB\n",
       "795       LB\n",
       "796       LB\n",
       "797       LB\n",
       "798       LB\n",
       "799       LB\n",
       "800       LB\n",
       "801       LB\n",
       "802       LB\n",
       "803       LB\n",
       "804       LB\n",
       "805       LB\n",
       "806       LB\n",
       "807       LB\n",
       "1243    None\n",
       "1244    None\n",
       "1245    None\n",
       "1246    None\n",
       "1247    None\n",
       "1248    None\n",
       "1249    None\n",
       "1250    None\n",
       "1251    None\n",
       "1252    None\n",
       "1253    None\n",
       "1254    None\n",
       "1255    None\n",
       "1256    None\n",
       "1257    None\n",
       "1258    None\n",
       "1259    None\n",
       "1260    None\n",
       "1261    None\n",
       "1262    None\n",
       "1263    None\n",
       "1264    None\n",
       "1265    None\n",
       "1266    None\n",
       "1267    None\n",
       "1268    None\n",
       "1269    None\n",
       "1270    None\n",
       "1271    None\n",
       "1272    None\n",
       "1273    None\n",
       "1274    None\n",
       "1275    None\n",
       "1276    None\n",
       "1277    None\n",
       "1278    None\n",
       "1279    None\n",
       "1280    None\n",
       "1281    None\n",
       "1282    None\n",
       "1283    None\n",
       "1284    None\n",
       "1285    None\n",
       "1286    None\n",
       "1287    None\n",
       "1288    None\n",
       "1289    None\n",
       "1290    None\n",
       "1291    None\n",
       "1292    None\n",
       "1293    None\n",
       "1294    None\n",
       "1295    None\n",
       "1296    None\n",
       "1297    None\n",
       "1298    None\n",
       "1299    None\n",
       "1300    None\n",
       "1301    None\n",
       "1302    None\n",
       "1303    None\n",
       "1304    None\n",
       "1305    None\n",
       "1306    None\n",
       "1307    None\n",
       "1308    None\n",
       "1309    None\n",
       "1310    None\n",
       "1311    None\n",
       "1312    None\n",
       "1313    None\n",
       "1314    None\n",
       "1315    None\n",
       "1316    None\n",
       "1317    None\n",
       "1318    None\n",
       "1319    None\n",
       "1320    None\n",
       "1321    None\n",
       "1322    None\n",
       "1323    None\n",
       "1324    None\n",
       "1325    None\n",
       "1326    None\n",
       "1327    None\n",
       "1328    None\n",
       "1329    None\n",
       "1330    None\n",
       "1331    None\n",
       "1332    None\n",
       "1333    None\n",
       "1334    None\n",
       "1335    None\n",
       "1336    None\n",
       "1337    None\n",
       "1338    None\n",
       "1339    None\n",
       "1340    None\n",
       "1341    None\n",
       "1342    None\n",
       "1343    None\n",
       "1344    None\n",
       "1345    None\n",
       "1346    None\n",
       "1347    None\n",
       "1348    None\n",
       "1349    None\n",
       "1350    None\n",
       "1351    None\n",
       "1352    None\n",
       "1353    None\n",
       "1354    None\n",
       "1355    None\n",
       "1356    None\n",
       "1357    None\n",
       "1358    None\n",
       "1359    None\n",
       "1360    None\n",
       "1361    None\n",
       "1362    None\n",
       "1363    None\n",
       "1364    None\n",
       "1365    None\n",
       "1366    None\n",
       "1367    None\n",
       "1368    None\n",
       "1369    None\n",
       "1370    None\n",
       "1371    None\n",
       "1372    None\n",
       "1373    None\n",
       "1374    None\n",
       "1375    None\n",
       "1376    None\n",
       "1377    None\n",
       "1378    None\n",
       "1379    None\n",
       "1380    None\n",
       "1381    None\n",
       "1382    None\n",
       "1383    None\n",
       "1384    None\n",
       "1385    None\n",
       "1386    None\n",
       "1387    None\n",
       "1388    None\n",
       "1389    None\n",
       "1390    None\n",
       "1391    None\n",
       "1392    None\n",
       "1393    None\n",
       "1394    None\n",
       "1395    None\n",
       "1396    None\n",
       "1397    None\n",
       "1398    None\n",
       "1399    None\n",
       "1400    None\n",
       "1401    None\n",
       "1402    None\n",
       "1403    None\n",
       "1404    None\n",
       "1405    None\n",
       "1406    None\n",
       "1407    None\n",
       "1408    None\n",
       "1409    None\n",
       "1410    None\n",
       "1411    None\n",
       "1412    None\n",
       "1413    None\n",
       "1414    None\n",
       "1415    None\n",
       "1416    None\n",
       "1417    None\n",
       "1418    None\n",
       "1419    None\n",
       "1420    None\n",
       "1421    None\n",
       "1422    None\n",
       "1423    None\n",
       "1424    None\n",
       "1425    None\n",
       "1426    None\n",
       "1427    None\n",
       "1428    None\n",
       "1429    None\n",
       "1430    None\n",
       "1431    None\n",
       "1432    None\n",
       "1433    None\n",
       "1434    None\n",
       "1435    None\n",
       "1436    None\n",
       "1437    None\n",
       "1438    None\n",
       "1439    None\n",
       "1440    None\n",
       "1441    None\n",
       "1442    None\n",
       "1443    None\n",
       "1444    None\n",
       "1445    None\n",
       "1446    None\n",
       "1447    None\n",
       "1448    None\n",
       "1449    None\n",
       "1450    None\n",
       "1451    None\n",
       "1452    None\n",
       "1453    None\n",
       "1454    None\n",
       "1455    None\n",
       "1456    None\n",
       "1457    None\n",
       "1458    None\n",
       "1459    None\n",
       "1460    None\n",
       "1461    None\n",
       "1462    None\n",
       "1463    None\n",
       "1464    None\n",
       "1465    None\n",
       "1466    None\n",
       "1467    None\n",
       "1468    None\n",
       "1469    None\n",
       "1470    None\n",
       "1471    None\n",
       "1472    None\n",
       "1473    None\n",
       "1474    None\n",
       "1475    None\n",
       "1476    None\n",
       "1477    None\n",
       "1478    None\n",
       "1479    None\n",
       "1480    None\n",
       "1481    None\n",
       "1482    None\n",
       "1483    None\n",
       "1484    None\n",
       "1485    None\n",
       "1486    None\n",
       "1487    None\n",
       "1488    None\n",
       "1489    None\n",
       "1490    None\n",
       "1491    None\n",
       "1492    None\n",
       "1493    None\n",
       "1494    None\n",
       "1495    None\n",
       "1496    None\n",
       "1497    None\n",
       "1498    None\n",
       "1499    None\n",
       "1500    None\n",
       "1501    None\n",
       "1502    None\n",
       "1503    None\n",
       "1504    None\n",
       "1505    None\n",
       "1506    None\n",
       "1507    None\n",
       "1508    None\n",
       "1509    None\n",
       "1510    None\n",
       "1511    None\n",
       "1512    None\n",
       "1513    None\n",
       "1514    None\n",
       "1515    None\n",
       "1516    None\n",
       "1517    None\n",
       "1518    None\n",
       "1519    None\n",
       "1520    None\n",
       "1521    None\n",
       "1522    None\n",
       "1523    None\n",
       "1524    None\n",
       "1525    None\n",
       "1526    None\n",
       "1527    None\n",
       "1528    None\n",
       "1529    None\n",
       "1530    None\n",
       "1531    None\n",
       "1532    None\n",
       "1533    None\n",
       "1534    None\n",
       "1535    None\n",
       "1536    None\n",
       "1537    None\n",
       "1538    None\n",
       "1539    None\n",
       "1540    None\n",
       "1541    None\n",
       "1542    None\n",
       "1543    None\n",
       "1544    None\n",
       "1545    None\n",
       "1546    None\n",
       "1547    None\n",
       "1548    None\n",
       "1549    None\n",
       "1550    None\n",
       "1551    None\n",
       "1552    None\n",
       "1553    None\n",
       "1554    None\n",
       "1555    None\n",
       "1556    None\n",
       "1557    None\n",
       "1558    None\n",
       "1559    None\n",
       "1560    None\n",
       "1561    None\n",
       "1562    None\n",
       "1563    None\n",
       "1564    None\n",
       "1565    None\n",
       "1566    None\n",
       "1567    None\n",
       "1568    None\n",
       "1569    None\n",
       "1570    None\n",
       "1571    None\n",
       "1572    None\n",
       "1573    None\n",
       "1574    None\n",
       "1575    None\n",
       "1576    None\n",
       "1577    None\n",
       "1578    None\n",
       "1579    None\n",
       "1580    None\n",
       "1581    None\n",
       "1582    None\n",
       "1583    None\n",
       "1584    None\n",
       "1585    None\n",
       "1586    None\n",
       "1587    None\n",
       "1588    None\n",
       "1589    None\n",
       "1590    None\n",
       "1591    None\n",
       "1592    None\n",
       "1593    None\n",
       "1594    None\n",
       "1595    None\n",
       "1596    None\n",
       "1597    None\n",
       "1598    None\n",
       "1599    None\n",
       "1600    None\n",
       "1601    None\n",
       "1602    None\n",
       "1603    None\n",
       "1604    None\n",
       "1605    None\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Li7', 'Be9', 'B11', 'Mg24', 'Al27', 'Si28', 'P31', 'S33', 'K39',\n",
       "       'Ca42', 'Sc45', 'Ti47', 'V51', 'Cr52', 'Mn55', 'Fe56', 'Co59',\n",
       "       'Ni60', 'Cu63', 'Zn68', 'Ga69', 'Ge72', 'As75', 'Rb85', 'Sr88',\n",
       "       'Y89', 'Zr90', 'Nb93', 'Mo95', 'Cd111', 'In115', 'Sn118', 'Cs133',\n",
       "       'Ba137', 'La139', 'Ce140', 'Pr141', 'Nd146', 'Sm147', 'Eu153',\n",
       "       'Gd157', 'Tb159', 'Dy163', 'Ho165', 'Er166', 'Tm169', 'Yb172',\n",
       "       'Lu175', 'Hf178', 'Ta181', 'Pb208', 'Th232'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.columns.values[features_start:features_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'site_frequencies_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "site_frequencies_df = pd.DataFrame(my_data.Site.value_counts()).reset_index(drop = False).rename(columns = {'Site':'Number of Observations', 'index':'Site'})\n",
    "%store site_frequencies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw sample names including sample sites and artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FH', 'ER', 'WW', 'TC', 'CS', 'BC', 'KQ', 'AR', 'SL', 'FG', 'WB',\n",
       "       'BX', 'PF', 'BM', 'WH', 'SQ', 'BP', 'WN', 'BH', 'PH', 'LB', 'AB',\n",
       "       'LV', 'BR', 'KY', 'BF', 'ST', 'SH', 'CF', 'BG', 'AC', 'CR', 'GH',\n",
       "       'PX', 'WF', 'DH', 'NMAG_Gold', 'NMW_Gold', 'NMWGwern', 'UBSS',\n",
       "       'Cefn', 'Stockley', 'Pucha', 'Woodbury', 'Pimple', 'Wellington',\n",
       "       'Lyonshall', 'SymondsYatE', 'Madawg', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data['Site'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions for making target classes for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_classes_grouped_reduced(row):\n",
    "    if row['Geology'] == 'Bedrock':\n",
    "        return(row['Site'])\n",
    "    elif row['Geology'] == 'Superficial':\n",
    "        if row['Region'] == 'SV' or row['Region'] == 'SE':\n",
    "            return('SV_SE')\n",
    "        else:\n",
    "            return(row['Region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### targets for classification are made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['class'] = my_data.apply(make_classes_grouped_reduced, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove bedrock site 'BP' because class-specific F1 score was very bad due to limited sample number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = my_data[my_data['Site']!='BP']\n",
    "my_data = my_data[my_data['Site']!='BX']\n",
    "\n",
    "\n",
    "if bedrock_only:\n",
    "    my_superficial = my_data[my_data['Geology'] == 'Superficial']\n",
    "    my_data = my_data[my_data['Geology'] != 'Superficial']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop_semi_bedrock:\n",
    "    my_data = my_data[(my_data['class'] != 'BM') & (my_data['class'] != 'BC') & (my_data['class'] != 'BP') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FH', 'ER', 'WW', 'TC', 'CS', 'KQ', 'AR', 'SL', 'FG', 'WB', 'PF',\n",
       "       'WH', 'SQ', 'WN', 'BH', 'PH', 'LB', None], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove '<' signs and commas from feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 23585.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21649.69it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22374.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be9\n",
      "B11\n",
      "Mg24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21754.34it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21698.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al27\n",
      "Si28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22226.71it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22312.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P31\n",
      "S33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22487.74it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22413.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K39\n",
      "Ca42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21194.19it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20773.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sc45\n",
      "Ti47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 23362.94it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22160.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V51\n",
      "Cr52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22375.93it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22626.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mn55\n",
      "Fe56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21276.87it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20667.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co59\n",
      "Ni60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21526.72it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20390.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cu63\n",
      "Zn68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22932.38it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22035.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ga69\n",
      "Ge72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20712.09it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21751.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22727.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rb85\n",
      "Sr88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20336.00it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22866.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y89\n",
      "Zr90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22119.41it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 18263.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb93\n",
      "Mo95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21106.86it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 18828.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cd111\n",
      "In115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20783.29it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20150.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sn118\n",
      "Cs133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22293.22it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21950.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ba137\n",
      "La139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21711.96it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21930.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce140\n",
      "Pr141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22155.85it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 20061.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nd146\n",
      "Sm147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22251.11it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 22093.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu153\n",
      "Gd157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21380.74it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21569.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tb159\n",
      "Dy163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21098.46it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21316.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho165\n",
      "Er166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21233.47it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21253.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tm169\n",
      "Yb172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21688.83it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21163.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lu175\n",
      "Hf178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21346.81it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21442.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ta181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21149.94it/s]\n",
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21399.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pb208\n",
      "Th232\n",
      "U238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1087/1087 [00:00<00:00, 21336.12it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20627.96it/s]\n",
      "Pandas Apply:   0%|          | 0/435 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Li7\n",
      "Be9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19686.47it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20390.28it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 16688.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B11\n",
      "Mg24\n",
      "Al27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19194.59it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 18813.77it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 17828.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si28\n",
      "P31\n",
      "S33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20238.51it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 18958.64it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19138.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K39\n",
      "Ca42\n",
      "Sc45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19288.74it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19719.45it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19762.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ti47\n",
      "V51\n",
      "Cr52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19919.45it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20661.83it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 16832.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mn55\n",
      "Fe56\n",
      "Co59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 18721.50it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20400.54it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19718.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ni60\n",
      "Cu63\n",
      "Zn68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20105.37it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19253.53it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 18476.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ga69\n",
      "Ge72\n",
      "As75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20614.44it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20291.18it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 21111.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rb85\n",
      "Sr88\n",
      "Y89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19716.47it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20817.66it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20308.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zr90\n",
      "Nb93\n",
      "Mo95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20281.26it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20704.27it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19226.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cd111\n",
      "In115\n",
      "Sn118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20614.91it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 17178.44it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19376.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cs133\n",
      "Ba137\n",
      "La139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20327.81it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 13817.74it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20389.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce140\n",
      "Pr141\n",
      "Nd146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19033.79it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19704.75it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20659.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sm147\n",
      "Eu153\n",
      "Gd157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19825.51it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19955.40it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20762.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tb159\n",
      "Dy163\n",
      "Ho165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20015.38it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 18841.17it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20339.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Er166\n",
      "Tm169\n",
      "Yb172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 21444.03it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19451.40it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 17977.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lu175\n",
      "Hf178\n",
      "Ta181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 18783.37it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 19653.60it/s]\n",
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 21091.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pb208\n",
      "Th232\n",
      "U238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 435/435 [00:00<00:00, 20606.99it/s]\n"
     ]
    }
   ],
   "source": [
    "my_data = clean_columns(my_data, 9, -1)    \n",
    "my_superficial = clean_columns(my_superficial, 9, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualise na values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.set(rc={'figure.figsize':(20.7,50)})\n",
    "sns.heatmap(my_data.isna(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove rows where there are all element abundances are na values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = my_data.dropna(subset=my_data.columns.values[9:-1], how = 'all' , axis = 0)\n",
    "my_superficial = my_superficial.dropna(subset=my_superficial.columns.values[9:-1], how = 'all' , axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into 'train_data' and 'test_data', the former consists of samples from known geological sites and the latter from flint artefacts fow which the original geological source site is unknown and to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_split_geological, my_data_split_artefacts = split_data(my_data, 'Geology','Artefacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute na values with feature mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmorse/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/rmorse/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for column_name in my_data_split_geological.columns.values[9:-1]:\n",
    "    my_data_split_geological[column_name] = my_data_split_geological[column_name].fillna(my_data_split_geological[column_name].mean()) \n",
    "\n",
    "for column_name in my_data_split_artefacts.columns.values[9:-1]:\n",
    "    my_data_split_artefacts[column_name] = my_data_split_artefacts[column_name].fillna(my_data_split_artefacts[column_name].mean())  \n",
    "    \n",
    "for column_name in my_superficial.columns.values[9:-1]:\n",
    "    my_superficial[column_name] = my_superficial[column_name].fillna(my_superficial[column_name].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers defined as any values that exceed 2 standard deviations from the mean, such values are changed to the mean for that variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25188.19it/s]\n",
      "/home/rmorse/developer/machine_learning/paper_1_notebooks/functions/preproccessing.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data[col_name]= data.swifter.apply(impute_outliers_geo, axis = 1)\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 22396.22it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 22691.12it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 21155.11it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25146.75it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25231.51it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23245.28it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25341.03it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25130.94it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 22957.00it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 26067.16it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 21200.43it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25083.22it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24631.57it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 22822.04it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25545.93it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24032.56it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24825.97it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23255.84it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24554.50it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25341.47it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24827.44it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24860.00it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24232.86it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25620.14it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25951.30it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24771.19it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24291.13it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 27401.91it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24985.54it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24078.35it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23318.25it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25742.59it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 19693.83it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25903.17it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25585.78it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 25147.18it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24792.44it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 21959.38it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23552.67it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24535.72it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24386.51it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23236.77it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24789.07it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23655.16it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23573.40it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23303.36it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23852.11it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24067.44it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24351.92it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 23181.05it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 24906.67it/s]\n",
      "Pandas Apply: 100%|██████████| 696/696 [00:00<00:00, 26001.46it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 24276.23it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23038.65it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 24286.30it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 18230.43it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22673.94it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22275.53it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22120.83it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22334.35it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23189.54it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22600.90it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22015.59it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21512.59it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21861.33it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 25451.89it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22815.28it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22298.69it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21785.94it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22238.11it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21393.50it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23338.48it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21196.33it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22868.74it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22535.34it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21888.36it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21361.38it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22858.79it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22531.67it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23077.76it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22691.51it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 25428.09it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23072.52it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22438.03it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21148.63it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22926.25it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23527.09it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22308.49it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22533.33it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 24191.76it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23342.41it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23221.37it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 21188.95it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23969.72it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23296.34it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 19718.86it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22618.02it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 24234.88it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 24360.52it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23729.87it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 20805.88it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 22242.99it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 20686.02it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 24049.60it/s]\n",
      "Pandas Apply: 100%|██████████| 363/363 [00:00<00:00, 23170.13it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24155.33it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24503.22it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 25640.53it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 22761.91it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23154.89it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23944.33it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24574.67it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23545.13it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24876.63it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24910.15it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 21594.87it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 25154.99it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23896.96it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 25161.28it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23001.16it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 22771.07it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 20629.60it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24641.17it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23812.48it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23286.42it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23798.41it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 20989.74it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24169.83it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 21925.43it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24035.81it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 20538.87it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24113.22it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24999.51it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23455.22it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24564.67it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 25898.54it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23112.65it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 21780.47it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 22657.74it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 22704.30it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23817.49it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24004.92it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24623.09it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23523.13it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24054.31it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24012.24it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23768.13it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23510.00it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23101.16it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23505.43it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23619.41it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24844.57it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 24285.80it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 23502.07it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 22992.11it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 21017.25it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 22855.51it/s]\n",
      "Pandas Apply: 100%|██████████| 432/432 [00:00<00:00, 22967.92it/s]\n"
     ]
    }
   ],
   "source": [
    "my_data_split_geological = replace_outliers(my_data_split_geological, features_start, features_end, num_stds = 2)\n",
    "my_data_split_artefacts = replace_outliers(my_data_split_artefacts, features_start, features_end, num_stds = 2)\n",
    "my_superficial = replace_outliers(my_superficial, features_start, features_end, num_stds = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bedrock']\n",
      "['Artefacts']\n",
      "['Superficial']\n"
     ]
    }
   ],
   "source": [
    "print(my_data_split_geological['Geology'].unique())\n",
    "print(my_data_split_artefacts['Geology'].unique())\n",
    "print(my_superficial['Geology'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = my_data_split_geological.copy(deep = True)\n",
    "test_data = my_data_split_artefacts.copy(deep = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label encode the class to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bedrock_only:\n",
    "    train_data_formodel = train_data[train_data['Geology'] == 'Bedrock'].copy(deep = True)\n",
    "    train_data_formodel['class'], uniques = pd.factorize(train_data_formodel['class'])\n",
    "else:\n",
    "    train_data_formodel = train_data.copy(deep = True)\n",
    "    train_data_formodel['class'], uniques = pd.factorize(train_data_formodel['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_formodel' (DataFrame)\n",
      "Stored 'train_data' (DataFrame)\n",
      "Stored 'test_data' (DataFrame)\n",
      "Stored 'my_data' (DataFrame)\n",
      "Stored 'uniques' (Index)\n"
     ]
    }
   ],
   "source": [
    "%store train_data_formodel\n",
    "%store train_data\n",
    "%store test_data\n",
    "%store my_data\n",
    "%store uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preproccessing for dimensionality reduction and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### four datasets are created, one containing all train data (bedrock and superficial types), one containing just bedrock types, one containing just superficial types and one containing the artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#element_data_train = train_data[train_data.columns.values[9:-1]]\n",
    "element_data_train_bedrock = train_data[train_data.columns.values[9:-1]]\n",
    "element_data_train_superficial = my_superficial[my_superficial.columns.values[9:-1]]\n",
    "element_data_test = test_data[test_data.columns.values[9:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features are standardised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scaler_train = StandardScaler()\n",
    "my_scaler_train_bedrock = StandardScaler()\n",
    "my_scaler_train_superficial = StandardScaler()\n",
    "my_scaler_test = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#element_data_train_scaled = my_scaler_train.fit_transform(element_data_train)\n",
    "element_data_train_bedrock_scaled = my_scaler_train_bedrock.fit_transform(element_data_train_bedrock)\n",
    "element_data_train_superficial_scaled = my_scaler_train_superficial.fit_transform(element_data_train_superficial)\n",
    "element_data_test_scaled = my_scaler_test.fit_transform(element_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Distributed Stochastic Neighbour Embedding is done on the four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 696 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 696 samples in 0.067s...\n",
      "[t-SNE] Computed conditional probabilities for sample 696 / 696\n",
      "[t-SNE] Mean sigma: 2.194450\n",
      "[t-SNE] Computed conditional probabilities in 0.040s\n",
      "[t-SNE] Iteration 50: error = 72.6145859, gradient norm = 0.4021802 (50 iterations in 0.320s)\n",
      "[t-SNE] Iteration 100: error = 73.0112534, gradient norm = 0.3905257 (50 iterations in 0.320s)\n",
      "[t-SNE] Iteration 150: error = 72.5663605, gradient norm = 0.4193480 (50 iterations in 0.345s)\n",
      "[t-SNE] Iteration 200: error = 73.5665207, gradient norm = 0.4036619 (50 iterations in 0.329s)\n",
      "[t-SNE] Iteration 250: error = 74.1057205, gradient norm = 0.3846155 (50 iterations in 0.334s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 74.105721\n",
      "[t-SNE] Iteration 300: error = 1.2320886, gradient norm = 0.0046994 (50 iterations in 0.226s)\n",
      "[t-SNE] Iteration 350: error = 1.1329243, gradient norm = 0.0006182 (50 iterations in 0.212s)\n",
      "[t-SNE] Iteration 400: error = 1.1012520, gradient norm = 0.0007823 (50 iterations in 0.209s)\n",
      "[t-SNE] Iteration 450: error = 1.0894717, gradient norm = 0.0004048 (50 iterations in 0.204s)\n",
      "[t-SNE] Iteration 500: error = 1.0854782, gradient norm = 0.0001638 (50 iterations in 0.208s)\n",
      "[t-SNE] Iteration 550: error = 1.0824929, gradient norm = 0.0002203 (50 iterations in 0.206s)\n",
      "[t-SNE] Iteration 600: error = 1.0806736, gradient norm = 0.0001727 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 650: error = 1.0798759, gradient norm = 0.0001107 (50 iterations in 0.212s)\n",
      "[t-SNE] Iteration 700: error = 1.0795071, gradient norm = 0.0001133 (50 iterations in 0.210s)\n",
      "[t-SNE] Iteration 750: error = 1.0786992, gradient norm = 0.0001281 (50 iterations in 0.209s)\n",
      "[t-SNE] Iteration 800: error = 1.0778770, gradient norm = 0.0001705 (50 iterations in 0.213s)\n",
      "[t-SNE] Iteration 850: error = 1.0757366, gradient norm = 0.0001024 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 900: error = 1.0750681, gradient norm = 0.0001056 (50 iterations in 0.216s)\n",
      "[t-SNE] Iteration 950: error = 1.0747648, gradient norm = 0.0000867 (50 iterations in 0.213s)\n",
      "[t-SNE] Iteration 1000: error = 1.0746268, gradient norm = 0.0001065 (50 iterations in 0.221s)\n",
      "[t-SNE] Iteration 1050: error = 1.0746760, gradient norm = 0.0000737 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 1100: error = 1.0745194, gradient norm = 0.0000794 (50 iterations in 0.212s)\n",
      "[t-SNE] Iteration 1150: error = 1.0743593, gradient norm = 0.0000498 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 1200: error = 1.0741662, gradient norm = 0.0000649 (50 iterations in 0.216s)\n",
      "[t-SNE] Iteration 1250: error = 1.0740312, gradient norm = 0.0000684 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 1300: error = 1.0740697, gradient norm = 0.0001010 (50 iterations in 0.216s)\n",
      "[t-SNE] Iteration 1350: error = 1.0739125, gradient norm = 0.0000527 (50 iterations in 0.217s)\n",
      "[t-SNE] Iteration 1400: error = 1.0739416, gradient norm = 0.0000667 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 1450: error = 1.0739279, gradient norm = 0.0000474 (50 iterations in 0.216s)\n",
      "[t-SNE] Iteration 1500: error = 1.0739448, gradient norm = 0.0000865 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 1550: error = 1.0738297, gradient norm = 0.0000757 (50 iterations in 0.217s)\n",
      "[t-SNE] Iteration 1600: error = 1.0737736, gradient norm = 0.0000761 (50 iterations in 0.222s)\n",
      "[t-SNE] Iteration 1650: error = 1.0738078, gradient norm = 0.0000618 (50 iterations in 0.214s)\n",
      "[t-SNE] Iteration 1700: error = 1.0737956, gradient norm = 0.0000742 (50 iterations in 0.219s)\n",
      "[t-SNE] Iteration 1750: error = 1.0736872, gradient norm = 0.0000474 (50 iterations in 0.217s)\n",
      "[t-SNE] Iteration 1800: error = 1.0737040, gradient norm = 0.0000914 (50 iterations in 0.215s)\n",
      "[t-SNE] Iteration 1850: error = 1.0737294, gradient norm = 0.0000488 (50 iterations in 0.219s)\n",
      "[t-SNE] Iteration 1900: error = 1.0737776, gradient norm = 0.0000581 (50 iterations in 0.219s)\n",
      "[t-SNE] Iteration 1950: error = 1.0738162, gradient norm = 0.0000284 (50 iterations in 0.212s)\n",
      "[t-SNE] Iteration 2000: error = 1.0738257, gradient norm = 0.0000494 (50 iterations in 0.218s)\n",
      "[t-SNE] Iteration 2050: error = 1.0737807, gradient norm = 0.0000697 (50 iterations in 0.214s)\n",
      "[t-SNE] Iteration 2100: error = 1.0737343, gradient norm = 0.0000593 (50 iterations in 0.223s)\n",
      "[t-SNE] Iteration 2100: did not make any progress during the last 300 episodes. Finished.\n",
      "[t-SNE] KL divergence after 2100 iterations: 1.073734\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 432 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 432 samples in 0.025s...\n",
      "[t-SNE] Computed conditional probabilities for sample 432 / 432\n",
      "[t-SNE] Mean sigma: 2.389667\n",
      "[t-SNE] Computed conditional probabilities in 0.025s\n",
      "[t-SNE] Iteration 50: error = 68.3014374, gradient norm = 0.5010166 (50 iterations in 0.182s)\n",
      "[t-SNE] Iteration 100: error = 69.6638565, gradient norm = 0.4785686 (50 iterations in 0.191s)\n",
      "[t-SNE] Iteration 150: error = 69.4635468, gradient norm = 0.5012308 (50 iterations in 0.187s)\n",
      "[t-SNE] Iteration 200: error = 69.1313248, gradient norm = 0.4979854 (50 iterations in 0.176s)\n",
      "[t-SNE] Iteration 250: error = 70.0408859, gradient norm = 0.4751097 (50 iterations in 0.180s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.040886\n",
      "[t-SNE] Iteration 300: error = 0.9154649, gradient norm = 0.0039472 (50 iterations in 0.145s)\n",
      "[t-SNE] Iteration 350: error = 0.8734978, gradient norm = 0.0004912 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 400: error = 0.8634536, gradient norm = 0.0002614 (50 iterations in 0.129s)\n",
      "[t-SNE] Iteration 450: error = 0.8591237, gradient norm = 0.0001694 (50 iterations in 0.133s)\n",
      "[t-SNE] Iteration 500: error = 0.8576637, gradient norm = 0.0001098 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 550: error = 0.8572168, gradient norm = 0.0000794 (50 iterations in 0.136s)\n",
      "[t-SNE] Iteration 600: error = 0.8564315, gradient norm = 0.0000816 (50 iterations in 0.133s)\n",
      "[t-SNE] Iteration 650: error = 0.8564563, gradient norm = 0.0000938 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 700: error = 0.8563209, gradient norm = 0.0001106 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 750: error = 0.8561734, gradient norm = 0.0000688 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 800: error = 0.8562446, gradient norm = 0.0000500 (50 iterations in 0.135s)\n",
      "[t-SNE] Iteration 850: error = 0.8560773, gradient norm = 0.0000486 (50 iterations in 0.138s)\n",
      "[t-SNE] Iteration 900: error = 0.8560734, gradient norm = 0.0000529 (50 iterations in 0.139s)\n",
      "[t-SNE] Iteration 950: error = 0.8558979, gradient norm = 0.0000990 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 1000: error = 0.8559440, gradient norm = 0.0001210 (50 iterations in 0.132s)\n",
      "[t-SNE] Iteration 1050: error = 0.8558060, gradient norm = 0.0000566 (50 iterations in 0.133s)\n",
      "[t-SNE] Iteration 1100: error = 0.8558529, gradient norm = 0.0000434 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 1150: error = 0.8557441, gradient norm = 0.0000490 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 1200: error = 0.8556973, gradient norm = 0.0000646 (50 iterations in 0.132s)\n",
      "[t-SNE] Iteration 1250: error = 0.8556895, gradient norm = 0.0000576 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 1300: error = 0.8557404, gradient norm = 0.0000647 (50 iterations in 0.133s)\n",
      "[t-SNE] Iteration 1350: error = 0.8557310, gradient norm = 0.0000588 (50 iterations in 0.134s)\n",
      "[t-SNE] Iteration 1400: error = 0.8557144, gradient norm = 0.0000586 (50 iterations in 0.136s)\n",
      "[t-SNE] Iteration 1450: error = 0.8557412, gradient norm = 0.0000498 (50 iterations in 0.132s)\n",
      "[t-SNE] Iteration 1500: error = 0.8557305, gradient norm = 0.0000559 (50 iterations in 0.135s)\n",
      "[t-SNE] Iteration 1550: error = 0.8556932, gradient norm = 0.0000639 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 1600: error = 0.8556970, gradient norm = 0.0000553 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 1600: did not make any progress during the last 300 episodes. Finished.\n",
      "[t-SNE] KL divergence after 1600 iterations: 0.855697\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 363 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 363 samples in 0.019s...\n",
      "[t-SNE] Computed conditional probabilities for sample 363 / 363\n",
      "[t-SNE] Mean sigma: 2.634226\n",
      "[t-SNE] Computed conditional probabilities in 0.023s\n",
      "[t-SNE] Iteration 50: error = 69.1382828, gradient norm = 0.4957461 (50 iterations in 0.148s)\n",
      "[t-SNE] Iteration 100: error = 72.5687408, gradient norm = 0.4725733 (50 iterations in 0.153s)\n",
      "[t-SNE] Iteration 150: error = 69.7755051, gradient norm = 0.4938209 (50 iterations in 0.163s)\n",
      "[t-SNE] Iteration 200: error = 72.4324036, gradient norm = 0.4680220 (50 iterations in 0.157s)\n",
      "[t-SNE] Iteration 250: error = 71.0638275, gradient norm = 0.4829374 (50 iterations in 0.155s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 71.063828\n",
      "[t-SNE] Iteration 300: error = 1.0468413, gradient norm = 0.0043641 (50 iterations in 0.120s)\n",
      "[t-SNE] Iteration 350: error = 0.9833659, gradient norm = 0.0012835 (50 iterations in 0.109s)\n",
      "[t-SNE] Iteration 400: error = 0.9475088, gradient norm = 0.0013901 (50 iterations in 0.108s)\n",
      "[t-SNE] Iteration 450: error = 0.9222216, gradient norm = 0.0011122 (50 iterations in 0.113s)\n",
      "[t-SNE] Iteration 500: error = 0.9135063, gradient norm = 0.0006995 (50 iterations in 0.122s)\n",
      "[t-SNE] Iteration 550: error = 0.9082296, gradient norm = 0.0004502 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 600: error = 0.9017745, gradient norm = 0.0014291 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 650: error = 0.8905861, gradient norm = 0.0001789 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 700: error = 0.8900821, gradient norm = 0.0001171 (50 iterations in 0.116s)\n",
      "[t-SNE] Iteration 750: error = 0.8900330, gradient norm = 0.0000657 (50 iterations in 0.119s)\n",
      "[t-SNE] Iteration 800: error = 0.8897427, gradient norm = 0.0000720 (50 iterations in 0.114s)\n",
      "[t-SNE] Iteration 850: error = 0.8895415, gradient norm = 0.0000972 (50 iterations in 0.113s)\n",
      "[t-SNE] Iteration 900: error = 0.8894439, gradient norm = 0.0000811 (50 iterations in 0.113s)\n",
      "[t-SNE] Iteration 950: error = 0.8889126, gradient norm = 0.0001030 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 1000: error = 0.8776568, gradient norm = 0.0004591 (50 iterations in 0.111s)\n",
      "[t-SNE] Iteration 1050: error = 0.8769341, gradient norm = 0.0000901 (50 iterations in 0.111s)\n",
      "[t-SNE] Iteration 1100: error = 0.8768419, gradient norm = 0.0000621 (50 iterations in 0.109s)\n",
      "[t-SNE] Iteration 1150: error = 0.8766589, gradient norm = 0.0001116 (50 iterations in 0.112s)\n",
      "[t-SNE] Iteration 1200: error = 0.8768839, gradient norm = 0.0000813 (50 iterations in 0.119s)\n",
      "[t-SNE] Iteration 1250: error = 0.8767918, gradient norm = 0.0000624 (50 iterations in 0.126s)\n",
      "[t-SNE] Iteration 1300: error = 0.8770486, gradient norm = 0.0000777 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 1350: error = 0.8768248, gradient norm = 0.0000711 (50 iterations in 0.113s)\n",
      "[t-SNE] Iteration 1400: error = 0.8768657, gradient norm = 0.0000690 (50 iterations in 0.113s)\n",
      "[t-SNE] Iteration 1450: error = 0.8768588, gradient norm = 0.0000638 (50 iterations in 0.116s)\n",
      "[t-SNE] Iteration 1500: error = 0.8766367, gradient norm = 0.0000892 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 1550: error = 0.8767527, gradient norm = 0.0000781 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 1600: error = 0.8766111, gradient norm = 0.0000481 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 1650: error = 0.8765722, gradient norm = 0.0001011 (50 iterations in 0.129s)\n",
      "[t-SNE] Iteration 1700: error = 0.8763360, gradient norm = 0.0000826 (50 iterations in 0.113s)\n",
      "[t-SNE] Iteration 1750: error = 0.8762765, gradient norm = 0.0000488 (50 iterations in 0.115s)\n",
      "[t-SNE] Iteration 1800: error = 0.8761551, gradient norm = 0.0000694 (50 iterations in 0.119s)\n",
      "[t-SNE] Iteration 1850: error = 0.8762009, gradient norm = 0.0000626 (50 iterations in 0.117s)\n",
      "[t-SNE] Iteration 1900: error = 0.8762320, gradient norm = 0.0000845 (50 iterations in 0.117s)\n",
      "[t-SNE] Iteration 1950: error = 0.8761944, gradient norm = 0.0001246 (50 iterations in 0.118s)\n",
      "[t-SNE] Iteration 2000: error = 0.8762525, gradient norm = 0.0001076 (50 iterations in 0.114s)\n",
      "[t-SNE] Iteration 2050: error = 0.8763356, gradient norm = 0.0000518 (50 iterations in 0.111s)\n",
      "[t-SNE] Iteration 2100: error = 0.8764909, gradient norm = 0.0000421 (50 iterations in 0.122s)\n",
      "[t-SNE] Iteration 2150: error = 0.8763729, gradient norm = 0.0000818 (50 iterations in 0.114s)\n",
      "[t-SNE] Iteration 2150: did not make any progress during the last 300 episodes. Finished.\n",
      "[t-SNE] KL divergence after 2150 iterations: 0.876373\n"
     ]
    }
   ],
   "source": [
    "#my_tsne_train = TSNE(n_components=2, n_iter=10000, verbose=3, random_state=random_seed_state).fit_transform(element_data_train_scaled)\n",
    "my_tsne_bedrock_train = TSNE(n_components=2, n_iter=10000, verbose=3, random_state=random_seed_state).fit_transform(element_data_train_bedrock_scaled)\n",
    "my_tsne_superficial_train = TSNE(n_components=2, n_iter=10000, verbose=3, random_state=random_seed_state).fit_transform(element_data_train_superficial_scaled)\n",
    "my_tsne_test = TSNE(n_components=2, n_iter=10000, verbose=3, random_state=random_seed_state).fit_transform(element_data_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the t-SNE dimensions for the four datasets are put into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne_df_train = pd.DataFrame(data = my_tsne_train, columns = ['tsne1', 'tsne2'])\n",
    "tsne_df_bedrock_train = pd.DataFrame(data = my_tsne_bedrock_train, columns = ['tsne1', 'tsne2'])\n",
    "tsne_df_superficial_train = pd.DataFrame(data = my_tsne_superficial_train, columns = ['tsne1', 'tsne2'])\n",
    "tsne_df_test = pd.DataFrame(data = my_tsne_test, columns = ['tsne1', 'tsne2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets are stored for the purpose of two-dimensional visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'tsne_df_bedrock_train' (DataFrame)\n",
      "Stored 'tsne_df_superficial_train' (DataFrame)\n",
      "Stored 'tsne_df_test' (DataFrame)\n",
      "Stored 'my_superficial' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "#%store tsne_df_train\n",
    "\n",
    "%store tsne_df_bedrock_train\n",
    "%store tsne_df_superficial_train\n",
    "\n",
    "\n",
    "%store tsne_df_test\n",
    "\n",
    "%store my_superficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
